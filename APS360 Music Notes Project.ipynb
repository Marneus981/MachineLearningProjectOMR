{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"APS360 Music Notes Project.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"8Yc19fYyoCDt"},"source":["##Changelog"]},{"cell_type":"code","metadata":{"id":"SQIoKrCasfBz"},"source":["#Changelog\n"," \n","#March 16\n","  #Added MozartCNN, includes and training and accuracy codes\n","  #Added MozartF1Helper function to calculate input to first fully connected layer for simple CNNs\n","  #Added GoogLeNet inception block code\n"," \n","#March 18\n","  #Added smolMozartCNN (2 layers) with custom options for maxpooling on last layer\n","  #Added smolestMozartCNN (1 layer) with custom options for maxpooling on last layer\n","  #Modified the MozartF1Helper code to be able to handle custom options for maxpooling\n","  #Added github repo clone for data\n"," \n","#March 19\n","  #Made MozartF1Helper round down in the case the size is odd and not even (needs further investigation)\n","  #Added Saskias Data\n","  #Deleted GoogleLeNet implementation\n","  #Padded labels with blank notes\n","  #Got Data Loaders ready\n","  #Added non squared width implementation for baseline models and MozartF1Helper\n","  #Mirza and Nancy's model and training implementation has been added\n","\n","#March 19 TO DO\n","  #Implement optional maxpooling on MozartCNN\n","  #Fix dimensions on data tensors\n","  #Add instructions on default options for all models in MozartF1Helper\n","  #Train the baseline model(s)\n","  #Fix accuracy calculations\n","\n","#March 19 warnings\n","  #The accuracy was being done for one hot encoding, useless and had to create new accuracy\n","  #Fixed the training loop\n","  #New accuracy calculation is not working\n","\n","#March 20\n","  #\"Fixed\" accuracy\n","  #Did 1000 epochs for the baseline model\n","#March 20 TO DO\n","  #Test accurary with small tensors\n","  #Create a small dataset for overfitting  \n","\n","#March 20/21\n","  # Debugged and implemented primary model architecture and training code\n","  # Primary model is capable of learning\n","  #TO DO: find better way of decoding CRNN output and computing accuracy\n","#March 26\n","  #Loaded 2048 samples to the github\n","#March 26 OMG WE GOTTA SOLVE IT QUICK\n","  #Data cant be used\n","#March 28\n","  #Primary model trains, overfits, computes accuracy correctly\n","  #Training accuracy ~99.96%, validation accuracy ~20%"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3bQnP8GloIzS"},"source":["##Set up"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mSGHH181vaOF","executionInfo":{"status":"ok","timestamp":1616797763776,"user_tz":360,"elapsed":2192,"user":{"displayName":"Marcos Madrigal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjdPHlmRPGmj3HQRnN3LXJ0NkC86RmADGU78ALR=s64","userId":"03986683852419586132"}},"outputId":"a1a8b7ca-dbc2-41b7-9e3d-87992813014c"},"source":["#Cloning the APS360Project repo\n","!git clone https://github.com/Marneus981/Aps360Project.git"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Cloning into 'Aps360Project'...\n","remote: Enumerating objects: 14308, done.\u001b[K\n","remote: Counting objects: 100% (14308/14308), done.\u001b[K\n","remote: Compressing objects: 100% (11287/11287), done.\u001b[K\n","remote: Total 14308 (delta 2246), reused 14305 (delta 2243), pack-reused 0\u001b[K\n","Receiving objects: 100% (14308/14308), 6.46 MiB | 33.06 MiB/s, done.\n","Resolving deltas: 100% (2246/2246), done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IMZrjolJ-Ya_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616791193130,"user_tz":240,"elapsed":3293,"user":{"displayName":"Mirza N","photoUrl":"","userId":"15555699542914153836"}},"outputId":"f1d28335-f8c6-4531-d0f9-d0f468377125"},"source":["#Only run if new data has been uploaded since last git clone\n","#%cd /content/Aps360Project\n","#!git pull"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/Aps360Project\n","Already up to date.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wioUZa1H_2Bd"},"source":["#Setup\n","\n","\n","#Imports taken from tutorial example\n","import torch\n","import os\n","import random\n","import numpy as np\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import matplotlib.pyplot as plt # plotting\n","import torch.optim as optim #gradient descent\n","import torchvision #to make things easier\n","from torchvision import models, datasets, transforms #migght be redundant\n","from torch.utils.data.sampler import SubsetRandomSampler# to use the data loader\n","from torch.utils.data import TensorDataset #load the tensordataset\n","from torch.utils.data import TensorDataset, DataLoader\n","from PIL import Image\n","\n","#Ill be using hardware acceleration by means of a GPU \n","use_cuda = True\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"h1LJGzXW__fD"},"source":["#For reproducibility\n","\n","seed_value= 0\n","\n","# 1. Set `PYTHONHASHSEED` environment variable at a fixed value\n","os.environ['PYTHONHASHSEED']=str(seed_value)\n","\n","# 2. Set `python` built-in pseudo-random generator at a fixed value\n","random.seed(seed_value)\n","\n","# 3. Set `numpy` pseudo-random generator at a fixed value\n","np.random.seed(seed_value)\n","\n","# 4. Set `pytorch` pseudo-random generator at a fixed value\n","torch.manual_seed(seed_value)\n","torch.cuda.manual_seed(seed_value)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AdPdrXyVn3Eb"},"source":["##Baseline Models"]},{"cell_type":"code","metadata":{"id":"ZjI9gwRyBEbY"},"source":["#Simple CNN Model\n","class MozartCNN(nn.Module):\n","  def __init__(self, input_channels,H,W,c1,c2,c3,f1,number_of_classes, kernel_size): \n","          super(MozartCNN, self).__init__()\n","          \n","          #Variables\n","          self.name = \"MozartCNN\"\n","          self.kernel_size = kernel_size\n","          self.input_channels = input_channels\n","          self.number_of_classes = number_of_classes\n","          self.H = H #Height input size\n","          self.W = W #Width input size\n","          self.f1 = f1\n","          \n","          #Layers\n","          self.conv1 = nn.Conv2d(in_channels=input_channels, out_channels=c1, kernel_size=kernel_size) #in input_channels*H*W out c1*(H-kernel_size+1)*(W-kernel_size+1)\n","\n","          self.pool = nn.MaxPool2d(kernel_size=2, stride=2) \n","          #in1 c1*(H-kernel_size+1)*(W-kernel_size+1) out c1*((H-kernel_size+1)/2)*((W-kernel_size+1)/2)\n","          #in2 c2*(((H-kernel_size+1)/2)-kernel_size+1)*(((W-kernel_size+1)/2)-kernel_size+1) out c2*((((H-kernel_size+1)/2)-kernel_size+1)/2)*((((W-kernel_size+1)/2)-kernel_size+1)/2)\n","          self.conv2 = nn.Conv2d(in_channels=c1, out_channels=c2, kernel_size=kernel_size) #in c1*((H-kernel_size+1)/2)*((W-kernel_size+1)/2) \\\n","                                                                                           #out c2*(((H-kernel_size+1)/2)-kernel_size+1)*(((W-kernel_size+1)/2)-kernel_size+1)\n","\n","          self.conv3 = nn.Conv2d(in_channels=c2, out_channels=c3, kernel_size=kernel_size) #in c2*((((H-kernel_size+1)/2)-kernel_size+1)/2)*((((W-kernel_size+1)/2)-kernel_size+1)/2)\n","                                                                                            #out c3*(((((H-kernel_size+1)/2)-kernel_size+1)/2)-kernel_size+1)*(((((W-kernel_size+1)/2)-kernel_size+1)/2)-kernel_size+1)\n","          self.fc1_in = c3*(((((H-kernel_size+1)//2)-kernel_size+1)//2)-kernel_size+1)*(((((W-kernel_size+1)//2)-kernel_size+1)//2)-kernel_size+1)\n","\n","          self.fc1 = nn.Linear(self.fc1_in, f1) #f1 needs to be divisible by two\n","          #flat in c3*(((((H-kernel_size+1)/2)-kernel_size+1)/2)-kernel_size+1)*(((((W-kernel_size+1)/2)-kernel_size+1)/2)-kernel_size+1)\n","          #out f1\n","          self.fc2 = nn.Linear(f1, number_of_classes) #to classify\n","          #in f1 out number_classes\n","\n","  def forward(self, x):\n","          #print(x.shape)\n","          x = self.pool(F.relu(self.conv1(x))) #Activation, first pool  set\n","          #print(x.shape)\n","          x = self.pool(F.relu(self.conv2(x))) #Activation, second pool  set\n","          #print(x.shape)\n","          x = F.relu(self.conv3(x))\n","          #print(x.shape)\n","          x = x.view(-1, self.fc1_in)\n","          #print(x.shape)\n","          x = F.relu(self.fc1(x))\n","          #print(x.shape) \n","          x = self.fc2(x)\n","          #print(x.shape)\n","          return x\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"A17K63fyhMp5"},"source":["#Simpler CNN model\n","class smolMozartCNN(nn.Module):\n","  def __init__(self, input_channels,H,W,c1,c2,f1,number_of_classes, kernel_size, second_conv_pool = False): \n","          super(smolMozartCNN, self).__init__()\n","          \n","          #Variables\n","          self.name = \"smolMozartCNN\"\n","          self.kernel_size = kernel_size\n","          self.input_channels = input_channels\n","          self.number_of_classes = number_of_classes\n","          self.H = H #Height input size\n","          self.W = W #Width input size\n","          self.f1 = f1\n","          self.second_conv_pool = second_conv_pool\n","          \n","          #Layers\n","          self.conv1 = nn.Conv2d(in_channels=input_channels, out_channels=c1, kernel_size=kernel_size) \n","\n","          self.pool = nn.MaxPool2d(kernel_size=2, stride=2) \n","          \n","          self.conv2 = nn.Conv2d(in_channels=c1, out_channels=c2, kernel_size=kernel_size) \n","                                                                                           \n","\n","          if (second_conv_pool == True): #There is 2nd layer maxpooling\n","            self.fc1_in = c2*((((H-kernel_size+1)//2)-kernel_size+1)/2)*((((W-kernel_size+1)//2)-kernel_size+1)/2)\n","          elif (second_conv_pool == False): #There is no 2nd layer maxpooling\n","             self.fc1_in = c2*(((H-kernel_size+1)//2)-kernel_size+1)*(((W-kernel_size+1)//2)-kernel_size+1)\n","          \n","          self.fc1 = nn.Linear(self.fc1_in, f1) #f1 needs to be divisible by two\n","          self.fc2 = nn.Linear(f1, number_of_classes) #to classify\n","          #in f1 out number_classes\n","\n","  def forward(self, x):\n","          x = self.pool(F.relu(self.conv1(x))) #Activation, first pool  set\n","          if (self.second_conv_pool == True): #There is 2nd layer maxpooling\n","            x = self.pool(F.relu(self.conv2(x))) \n","          elif (self.second_conv_pool == False): #There is no 2nd layer maxpooling\n","             x = F.relu(self.conv2(x)) \n","          x = x.view(-1, self.fc1_in)\n","          x = F.relu(self.fc1(x)) \n","          x = self.fc2(x)\n","          return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZJBZEgJZhy8H"},"source":["#Simplest CNN model\n","class smolestMozartCNN(nn.Module):\n","  def __init__(self, input_channels,H,W,c1,f1,number_of_classes, kernel_size,first_conv_pool = False): \n","          super(smolestMozartCNN, self).__init__()\n","          \n","          #Variables\n","          self.name = \"smolestMozartCNN\"\n","          self.kernel_size = kernel_size\n","          self.input_channels = input_channels\n","          self.number_of_classes = number_of_classes\n","          self.H = H #Height input size\n","          self.W = W #Width input size\n","          self.f1 = f1\n","          self.first_conv_pool = first_conv_pool\n","          \n","          #Layers\n","          self.conv1 = nn.Conv2d(in_channels=input_channels, out_channels=c1, kernel_size=kernel_size) \n","\n","          self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n","\n","          if (first_conv_pool == True): #There is 1st layer maxpooling\n","            self.fc1_in = c1*((H-kernel_size+1)//2)*((W-kernel_size+1)//2)\n","          elif (first_conv_pool == False): #There is no 1st layer maxpooling\n","            self.fc1_in = c1*(H-kernel_size+1)*(W-kernel_size+1)\n","\n","          self.fc1 = nn.Linear(self.fc1_in, f1) #f1 needs to be divisible by two\n","          #out f1\n","          self.fc2 = nn.Linear(f1, number_of_classes) #to classify\n","          #in f1 out number_classes\n","\n","  def forward(self, x):\n","          if (self.first_conv_pool == True): #There is 2nd 1st maxpooling\n","            x = self.pool(F.relu(self.conv1(x))) \n","          elif (self.first_conv_pool == False): #There is no 1st layer maxpooling\n","             x = F.relu(self.conv1(x))\n","          \n","          x = x.view(-1, self.fc1_in)\n","          \n","          x = F.relu(self.fc1(x))\n","          \n","          x = self.fc2(x)\n","          \n","          return x"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fHjSXMumn8ZU"},"source":["##Accuracy"]},{"cell_type":"code","metadata":{"id":"dNDZtBC_N3vy"},"source":["#To obtain accracy with a basic data loader using torch.utils.data.DataLoader(training_dataset, batch_size=batches, shuffle=True) \n","def get_accuracy(model, loader):\n","\n","    correct = 0\n","    total = 0\n","    for imgs, labels in loader:\n","\n","        #############################################\n","        #To Enable GPU Usage\n","        if use_cuda and torch.cuda.is_available():\n","          imgs = imgs.cuda()\n","          labels = labels.cuda()\n","        #############################################\n","\n","        output = model(imgs)\n","        \n","        #select index with maximum prediction score\n","        pred = output.max(1, keepdim=True)[1]\n","        correct += pred.eq(labels.view_as(pred)).sum().item()\n","        total += output.shape[0]\n","\n","    return correct / total"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cCzA-x6tT59I"},"source":["            \n","def get_accuracy_multitarget(model, loader):\n","\n","    correct = 0\n","    total = 0\n","    for imgs, labels in loader:\n","\n","        #############################################\n","        #To Enable GPU Usage\n","        if use_cuda and torch.cuda.is_available():\n","          imgs = imgs.cuda()\n","          labels = labels.cuda()\n","        #############################################\n","\n","        output = model(imgs)\n","        output_round = torch.round(output)\n","        correct += float(torch.sum(output_round == labels))\n","        total += output.shape[0]*output.shape[1]\n","        \n","\n","    return correct / total\n","\n","#Test with small tensors           "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"imeRl_4hpqQc"},"source":["##Training for baseline"]},{"cell_type":"code","metadata":{"id":"x47nA5cpOhSa"},"source":["def train(model, training_loader,validation_loader, batches ,num_epochs=1, lr = 0.001, update = False, plot = False, save = False):\n","    #To use batch sizes we need to set them and prepare a DataLoader for each of the sets\n","\n","    #training_loader = torch.utils.data.DataLoader(training_dataset, batch_size=batches, shuffle=True) #Shuffle\n","    #validation_loader = torch.utils.data.DataLoader(validation_dataset, batch_size=batches,  shuffle=True)\n","    \n","\n","    criterion =  nn.MSELoss()\n","    #criterion =  nn.BCEWithLogitsLoss()\n","    #nn.CrossEntropyLoss() \n","    optimizer = optim.Adam(model.parameters(), lr=lr) \n","    train_acc, val_acc, train_loss, val_loss = [], [], [], []\n","    iterations = 0\n","    # training\n","    plot_epochs = 0\n","    for epoch in range(num_epochs):\n","        for imgs, labels in iter(training_loader):\n","          \n","          \n","            #############################################\n","            #To Enable GPU Usage\n","            if use_cuda and torch.cuda.is_available():\n","              imgs = imgs.cuda()\n","              labels = labels.cuda()\n","            #############################################\n","            \n","              \n","            out = model(imgs)             # forward pass\n","            #print(labels.shape)\n","            tr_loss = criterion(out, labels) # compute the total loss\n","            tr_loss.backward()               # backward pass (compute parameter updates)\n","            optimizer.step()              # make the updates for each parameter\n","            optimizer.zero_grad()         # a clean up step for PyTorch\n","            iterations =iterations+1\n","        for imgs, labels in iter(validation_loader):\n","            out = model(imgs)             # forward pass\n","            vl_loss = criterion(out, labels)\n","\n","        plot_epochs = plot_epochs +1\n","        # save the current training information\n","        val_loss.append(float(vl_loss))\n","        train_loss.append(float(tr_loss))\n","        train_acc.append(get_accuracy_multitarget(model, training_loader)) # compute training accuracy \n","        val_acc.append(get_accuracy_multitarget(model, validation_loader))  # compute validation accuracy\n","\n","        if (update):\n","          print(\"Epoch \", epoch+1, \"TrAcc: \",train_acc[epoch],\"ValAcc: \",val_acc[epoch],\"TrLoss: \",train_loss[epoch],\"ValLoss: \",val_loss[epoch], \"\\n\")\n","        if save and (epoch + 1) % 100 == 0:\n","          # Save the current model (checkpoint) to a file\n","          model_path = \"model_bs{0}_lr{1}_epoch{2}\".format(batches, lr, epoch + 1)\n","          torch.save(model.state_dict(), model_path)\n","\n","    # plotting\n","    \n","    plot_epochs_l = np.arange(1, plot_epochs + 1)\n","    if (plot):\n","\n","      print(\"Epochs: {0}, Iterations: {1}, Batch Size: {2}, Learning Rate: {3}\".format(plot_epochs, iterations, batches, lr))\n","      plt.title(\"Training Curve; Accuracy\")\n","      plt.plot(plot_epochs_l, train_acc, label=\"Train\")\n","      plt.plot(plot_epochs_l, val_acc, label=\"Validation\")\n","      plt.xlabel(\"Epochs\")\n","      plt.ylabel(\"Accuracy\")\n","      plt.legend(loc='best')\n","      plt.show()  \n","      plt.title(\"Training Curve; Loss\")\n","      plt.plot(plot_epochs_l, train_loss, label=\"Train\")\n","      plt.plot(plot_epochs_l, val_loss, label=\"Validation\")\n","      plt.xlabel(\"Epochs\")\n","      plt.ylabel(\"Loss\")\n","      plt.legend(loc='best')\n","      plt.show()\n","\n","    print(\"Final Training Accuracy: {}\".format(train_acc[-1]))\n","    print(\"Final Validation Accuracy: {}\".format(val_acc[-1]))\n","    print(\"Final Training Loss: {}\".format(train_loss[-1]))\n","    print(\"Final Validation Loss: {}\".format(val_loss[-1]))\n","\n","    print(\"Final Epochs: {}\".format(plot_epochs))\n","    print(\"Final Iterations: {}\".format(iterations))\n","\n","    return train_acc, val_acc, train_loss, val_loss"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"epiA_Rx6Tvum"},"source":["#Helper Function to calculate f1_in (input to first fully connected layer) for MozartCNN given input size\n","def MozartF1Helper(H,W,last_output_channel_sz,conv_layers = 3,kernel_sizes = [3,3,3],max_pooled = [True,True,False]): \n","  if (len(kernel_sizes)!=conv_layers or len(kernel_sizes)!=len(max_pooled) or len(max_pooled)!= conv_layers):\n","    print(\"ERROR: The number of kernel sizes and the maxpooling rules must equal number of convolutional layers !\")\n","    return 0\n","  Hnew = H\n","  Wnew = W\n","  i = 0\n","  for i in range(conv_layers-1):\n","    Hnew= Hnew-kernel_sizes[i]+1 #Conv layer\n","    Wnew= Wnew-kernel_sizes[i]+1\n","    if (max_pooled[i]):\n","      Hnew = Hnew//2 #Maxpooling layer\n","      Wnew = Wnew//2\n","  Hnew= Hnew-kernel_sizes[i+1]+1 #Last conv layer\n","  Wnew= Wnew-kernel_sizes[i+1]+1\n","  flat_sz = last_output_channel_sz*Hnew*Wnew\n","  return flat_sz, Hnew,Wnew,last_output_channel_sz\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"86KXTj7ubGnc","executionInfo":{"status":"ok","timestamp":1616791196559,"user_tz":240,"elapsed":6677,"user":{"displayName":"Mirza N","photoUrl":"","userId":"15555699542914153836"}},"outputId":"0c9135fc-01ce-4f88-e318-0eea5d2eba3e"},"source":["#Test\n","flat_sz, Hnew,Wnew,last_output_channel_sz = MozartF1Helper(224,224,20, kernel_sizes=[5,5,5],max_pooled = [True,True,False])\n","print(flat_sz)\n","print(Hnew)\n","print(Wnew)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["48020\n","49\n","49\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"pdN3hUaWqP2y"},"source":["##Data Loading"]},{"cell_type":"code","metadata":{"id":"wrrlk_7AtCXI"},"source":["#convert labels to integer encoding\n","\n","#helper functions\n","\n","letters_to_numbers =  {\n","  'C':0,\n","  'D':2,\n","  'E':4,\n","  'F':5,\n","  'G':7,\n","  'A':9,\n","  'B':11\n","  }\n","accidentals_to_numbers = {\n","    'x':2,\n","    '#':1,\n","    '':0,\n","    'n':0,\n","    'b':-1,\n","    'bb':-2\n","}\n","def letter_to_int(noteId, noteDict):\n","  #Get octave\n","  octaveNum = int(noteId[-1])\n","  #Get letter name\n","  letterName = noteId[0]\n","  letterNum = letters_to_numbers[letterName]\n","  #Get accidental  \n","  accidentalName = noteId[1:-1]\n","  accidentalNum = accidentals_to_numbers[accidentalName]\n","  #Add together\n","  noteNum = (octaveNum+1)*12+letterNum+accidentalNum\n","  noteDict[noteNum] = noteId\n","  return noteNum\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wD5F84m-xAQz"},"source":["# #Data loading\n","\n","data_path = \"/content/Aps360Project/Project_Data_Big\"\n","#extract images and labels from dataset folder and put into arrays\n","images = []\n","label = []\n","counter = 0\n","for root, dirs, files in os.walk(data_path):\n","  if counter > 2048:\n","    break\n","  counter+=1\n","  for file in files:\n","    filename = str(file)\n","    if (filename.endswith('.png') and not filename.startswith('._')):\n","      #print(str(root))\n","      filepath = str(root) + '/' + str(file)\n","      img = plt.imread(filepath)\n","      img_cropped = img[0:154, 0:1200]\n","      images.append(img_cropped)\n","    if (filename.endswith('.semantic') and not filename.startswith('._')):\n","      filepath = str(root) + '/' + str(file)\n","      f = open(filepath, 'r')\n","      contents = f.read()\n","      elements = contents.split(\"\\t\", 50)\n","      #print(elements)\n","      semantic = []\n","      for element in elements:\n","        #print(element)\n","        if element.startswith('note'):\n","          element = element[5:8]\n","          if element.endswith('_'):\n","            element = element[:-1]\n","          semantic.append(element)\n","\n","      label.append(semantic)\n","\n","\n","#example image and label\n","plt.imshow(images[3]) \n","print(label[3])\n","\n","\n","#call functions on label set to generate integer labels\n","int_label = []\n","noteDict = {}\n","for semantic in label:\n","  int_semantic = []\n","  for note in semantic:\n","    int_semantic.append(letter_to_int(note, noteDict))\n","  int_label.append(int_semantic)  \n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"r3c97n5Rsdeg"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VxyzEXe8swpO"},"source":["# #Data loading\n","\n","# data_path = '/content/Aps360Project/Project_Data_Big'\n","# save_path = '/content/Aps360Project/Data'\n","# #extract images and labels from dataset folder and put into arrays\n","# # images = []\n","# # label = []\n","# noteDict = {}\n","# counter = 0\n","# for root, dirs, files in os.walk(data_path):\n","#   if counter > 2048:\n","#     break\n","#   counter+=1\n","#   for file in files:\n","#     filename = str(file)\n","#     if (filename.endswith('.png') and not filename.startswith('._')):\n","#       #print(str(root))\n","#       filepath = str(root) + '/' + str(file)\n","#       img = plt.imread(filepath)\n","#       img_cropped = img[0:154, 0:1200]\n","#       #images.append(img_cropped)\n","#       torch.save(img_cropped, str(save_path) + '/Images/image' + str(counter)+'.pt')\n","\n","\n","#     if (filename.endswith('.semantic') and not filename.startswith('._')):\n","#       filepath = str(root) + '/' + str(file)\n","#       f = open(filepath, 'r')\n","#       contents = f.read()\n","#       elements = contents.split(\"\\t\", 50)\n","#       #print(elements)\n","#       semantic = []\n","#       for element in elements:\n","#         #print(element)\n","#         if element.startswith('note'):\n","#           element = element[5:8]\n","#           if element.endswith('_'):\n","#             element = element[:-1]\n","#           semantic.append(element)\n","\n","#       #label.append(semantic)\n","#       torch.save(semantic, str(save_path) + '/Labels/label' + str(counter)+'.pt')\n","#       for semantic in label:\n","#         int_semantic = []\n","#         for note in semantic:\n","#           int_semantic.append(letter_to_int(note, noteDict))\n","  \n","#         torch.save(int_semantic, str(save_path) + '/IntLabels/int_label' + str(counter)+'.pt')\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GGq21h2x0B2V","executionInfo":{"status":"ok","timestamp":1616800776146,"user_tz":360,"elapsed":264,"user":{"displayName":"Marcos Madrigal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjdPHlmRPGmj3HQRnN3LXJ0NkC86RmADGU78ALR=s64","userId":"03986683852419586132"}},"outputId":"084529ef-6f92-48ba-9c6b-27d4b318975d"},"source":["# counter = 0\n","# for root, dirs, files in os.walk(str(save_path)+ '/Semantics/'):\n","#   for file in files:\n","#     counter +=1\n","# print(counter)\n","# counter = 0\n","# for root, dirs, files in os.walk(str(save_path)+ '/Images/'):\n","#   for file in files:\n","#     counter +=1\n","# print(counter)\n","# counter = 0\n","# for root, dirs, files in os.walk(str(save_path)+ '/IntSemantics/'):\n","#   for file in files:\n","#     counter +=1\n","# print(counter)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2048\n","2048\n","2048\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zvNG_DIn8JAi"},"source":["#Create list of tensors (to be converted to a tensor)\n","image_tensors_list = [torch.from_numpy(item).float() for item in images]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LgCwiWNo4c82","executionInfo":{"status":"ok","timestamp":1616791213919,"user_tz":240,"elapsed":24009,"user":{"displayName":"Mirza N","photoUrl":"","userId":"15555699542914153836"}},"outputId":"065162c4-e615-432d-85b8-d06329aea15c"},"source":["#Code to figure out padding for data (images)\n","# for i in range(10):\n","#   print(image_tensors_list[i].shape)\n","# print(image_tensors_list[0].shape[0])\n","# print(image_tensors_list[0].shape[1])\n","# print(image_tensors_list[0].shape[2])\n","\n","max_along0 = 0\n","max_along1 = 0\n","for i in range(len(image_tensors_list)):\n","  if ( image_tensors_list[i].shape[0] > max_along0 ):\n","    max_along0 = image_tensors_list[i].shape[0]\n","  if ( image_tensors_list[i].shape[1] > max_along1 ):\n","    max_along1 = image_tensors_list[i].shape[1]\n","print(max_along0)\n","print(max_along1)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["154\n","1200\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rQpnNFDR18pH","executionInfo":{"status":"ok","timestamp":1616791213919,"user_tz":240,"elapsed":24002,"user":{"displayName":"Mirza N","photoUrl":"","userId":"15555699542914153836"}},"outputId":"f4ae8b8d-bb2a-4ec9-ae44-ee3b3ecc7b15"},"source":["#Find max lenght of labels for padding\n","def FindMaxLength(lst): \n","    maxList = max((x) for x in lst) \n","    maxLength = max(len(x) for x in lst ) \n","  \n","    return maxList, maxLength \n","maxList, maxLength  = FindMaxLength(int_label)\n","\n","print(maxLength)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["47\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"be642oGy7fuB"},"source":["#padding list of labels with blank notes (0s)\n","\n","for i in range(len(int_label)):\n","  int_label[i] += [0] * (maxLength - len( int_label[i]))\n","\n","#padding list of tensors (data) with a bunch or zeros\n","target = torch.zeros(30, 35, 512)\n","source = torch.ones(30, 35, 49)\n","\n","for i in range(len(image_tensors_list)):\n","  target = torch.zeros(max_along0, max_along1, 3)\n","  target[:image_tensors_list[i].shape[0], :image_tensors_list[i].shape[1], :] = image_tensors_list[i]\n","  image_tensors_list[i] = target\n","#convert image into a tensor\n","#create tensor of data\n","\n","\n","image_tensors_list_tensor = torch.stack(image_tensors_list)\n","print(image_tensors_list_tensor.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"thn0zsv0J6jE"},"source":["print(image_tensors_list_tensor.permute(0,3,1,2).size())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uCWkr-53KL_n"},"source":["image_tensors_list_tensor = image_tensors_list_tensor.permute(0,3,1,2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"j6fT4Fc013E4"},"source":["\n","\n","\n","#split labels\n","training_labels = int_label[:108]\n","validation_labels = int_label[108:144]\n","testing_labels = int_label[144:]\n","\n","#transform tensors to labels\n","\n","training_labels_tensor = torch.FloatTensor(training_labels)\n","validation_labels_tensor = torch.FloatTensor(validation_labels)\n","testing_labels_tensor = torch.FloatTensor(testing_labels)\n","\n","#split data (180 samples not 320)\n","# training_data = images[:108]\n","# validation_data = images[108:144]\n","# testing_data = images[144:]\n","\n","#split tensor data\n","training_tensor= image_tensors_list_tensor[:108]\n","validation_tensor = image_tensors_list_tensor[108:144]\n","testing_tensor = image_tensors_list_tensor[144:]\n","\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"A-lukhkKkh9n"},"source":["#Small loader for overfitting\n","small_labels = int_label[:5]\n","small_labels_tensor = torch.FloatTensor(small_labels)\n","small_tensor= image_tensors_list_tensor[:5]\n","small_dataset = TensorDataset(small_tensor,small_labels_tensor) # training dataset\n","small_loader = DataLoader(small_dataset,batch_size=5, shuffle=True) # create your dataloader"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CnWB2j9JLsFV","executionInfo":{"status":"ok","timestamp":1616275894194,"user_tz":360,"elapsed":3458,"user":{"displayName":"Marcos Madrigal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjdPHlmRPGmj3HQRnN3LXJ0NkC86RmADGU78ALR=s64","userId":"03986683852419586132"}},"outputId":"83e73362-394e-4f9d-e58c-35e740a6039d"},"source":["print(training_labels_tensor.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["torch.Size([108, 30])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7GQpwpIyKhkE","executionInfo":{"status":"ok","timestamp":1616275894195,"user_tz":360,"elapsed":3452,"user":{"displayName":"Marcos Madrigal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjdPHlmRPGmj3HQRnN3LXJ0NkC86RmADGU78ALR=s64","userId":"03986683852419586132"}},"outputId":"beaf33b9-3adf-4d18-e616-36bf564eb811"},"source":["print(image_tensors_list[0].shape)\n","print(len(image_tensors_list))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["torch.Size([154, 1200, 3])\n","180\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1IUL0kmxw6CW","executionInfo":{"status":"ok","timestamp":1616275894195,"user_tz":360,"elapsed":3445,"user":{"displayName":"Marcos Madrigal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjdPHlmRPGmj3HQRnN3LXJ0NkC86RmADGU78ALR=s64","userId":"03986683852419586132"}},"outputId":"da00a060-9ba9-4c10-84bb-4e86473e1420"},"source":["print(len(int_label))\n","print(len(training_labels))\n","print(len(validation_labels))\n","print(len(testing_labels))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["180\n","108\n","36\n","36\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ig3UFdTs-fBP"},"source":["batch_size = 32"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"v0H2kqv-9ycQ"},"source":["#\"Final\" datasets and dataloaders\n","training_dataset = TensorDataset(training_tensor,training_labels_tensor) # training dataset\n","training_loader = DataLoader(training_dataset,batch_size=batch_size, shuffle=True) # create your dataloader\n","validation_dataset = TensorDataset(validation_tensor,validation_labels_tensor) # training dataset\n","validation_loader = DataLoader(validation_dataset,batch_size=batch_size, shuffle=True) # create your dataloader\n","testing_dataset = TensorDataset(testing_tensor,testing_labels_tensor) # training dataset\n","testing_loader = DataLoader(testing_dataset,batch_size=batch_size, shuffle=True) # create your dataloader"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ah8hvS_kBTIe","executionInfo":{"status":"ok","timestamp":1616275894197,"user_tz":360,"elapsed":3430,"user":{"displayName":"Marcos Madrigal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjdPHlmRPGmj3HQRnN3LXJ0NkC86RmADGU78ALR=s64","userId":"03986683852419586132"}},"outputId":"ff103547-623e-4338-affc-53747e5447df"},"source":["flat_sz, Hnew,Wnew,last_output_channel_sz = MozartF1Helper(max_along0,max_along1,20,conv_layers = 3,kernel_sizes = [5,5,5],max_pooled = [True,True,False])\n","print(flat_sz)\n","print(Hnew)\n","print(Wnew)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["181660\n","31\n","293\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"U-jV2GkV_TIh"},"source":["#Baseline model training: MozartCNN\n","BaselineModel = MozartCNN(3,max_along0,max_along1,5,10, 20, 64,30,5)\n","train_acc_b0, val_acc_b0, train_loss_b0, val_loss_b0 = train(BaselineModel, training_loader,validation_loader,32, num_epochs=1000, lr = 0.001, update = True, plot = True, save = True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PsmtsMYukFit"},"source":["#Highest Training Accuracy on Epoch  910 TrAcc:  0.8089506172839506 ValAcc:  0.05092592592592592 TrLoss:  0.14224201440811157 ValLoss:  209.2037811279297\n","#As expected the baseline model does not allow for generalization "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GmguvBPZlKWN"},"source":["#Baseline model training: MozartCNN\n","BaselineModelOverfit = MozartCNN(3,max_along0,max_along1,5,10, 20, 64,30,5)\n","train_acc_b0, val_acc_b0, train_loss_b0, val_loss_b0 = train(BaselineModelOverfit, small_loader,small_loader,5, num_epochs=1000, lr = 0.001, update = True, plot = True, save = False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZkLae8g7KK8X"},"source":["# **Our Primary Model**\n","\n","This is a basic CRNN model; might be better to use pretrained model tho ahh"]},{"cell_type":"code","metadata":{"id":"Ty9NnOch23rU"},"source":["def conv_outdims(input_w, input_h, kn_size, padding=0, stride=1):\n","  output_w = int((input_w - kn_size + 2*padding) / stride) + 1\n","  output_h = int((input_h - kn_size + 2*padding) / stride) + 1\n","  return output_w, output_h"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zcqqo88cKRgs"},"source":["class MusicSheetCRNN(nn.Module):\n","  def __init__(self, input_w=1200, input_h=154, out_cn=5, kn_size=3, rnn_hid_units=128, number_of_classes=92):\n","    super(MusicSheetCRNN, self).__init__()\n","\n","    self.name = \"MusicSheetCRNN\"\n","\n","    # CNN layers\n","    self.conv1 = nn.Conv2d(3, out_cn, kn_size) #in_channels, out_chanels, kernel_size\n","    self.norm1 = nn.BatchNorm2d(out_cn)\n","    self.pool = nn.MaxPool2d(2, 2) #kernel_size, stride \n","    self.conv2 = nn.Conv2d(out_cn, out_cn * 2, kn_size) #in_channels, out_chanels (doubled), kernel_size\n","    self.norm2 = nn.BatchNorm2d(out_cn * 2)\n","    self.conv3 = nn.Conv2d(out_cn * 2, out_cn * 2 * 2, kn_size)\n","    self.norm3 = nn.BatchNorm2d(out_cn * 2 * 2)\n","    self.conv4 = nn.Conv2d(out_cn * 2 * 2, out_cn * 2 * 2 * 2, kn_size)\n","    self.norm4 = nn.BatchNorm2d(out_cn * 2 * 2 * 2)\n","\n","    # compute conv output dimensions\n","    conv1_out_w, conv1_out_h = conv_outdims(input_w, input_h, kn_size)\n","    pool1_out_w, pool1_out_h = conv_outdims(conv1_out_w, conv1_out_h, kn_size=2, stride=2)\n","    conv2_out_w, conv2_out_h = conv_outdims(pool1_out_w, pool1_out_h, kn_size)\n","    pool2_out_w, pool2_out_h = conv_outdims(conv2_out_w, conv2_out_h, kn_size=2, stride=2)\n","    conv3_out_w, conv3_out_h = conv_outdims(pool2_out_w, pool2_out_h, kn_size)\n","    pool3_out_w, pool3_out_h = conv_outdims(conv3_out_w, conv3_out_h, kn_size=2, stride=2)\n","    conv4_out_w, conv4_out_h = conv_outdims(pool3_out_w, pool3_out_h, kn_size)\n","    \n","    self.cnn_output_width = conv4_out_w\n","    self.cnn_output_height = conv4_out_h\n","    self.rnn_input_size = self.cnn_output_height * out_cn * 2 * 2 * 2\n","    \n","    # RNN layer\n","    self.rnn_hid_units = rnn_hid_units\n","    self.lstm = nn.LSTM(self.rnn_input_size, self.rnn_hid_units, num_layers=3, bidirectional=True, batch_first=True)\n","\n","    # prediction: fully connected layers\n","    self.fc1 = nn.Linear(self.rnn_hid_units * 2, number_of_classes)\n","\n","  def forward(self, x):\n","    # CNN\n","    x = self.pool(F.relu(self.norm1(self.conv1(x))))\n","    x = self.pool(F.relu(self.norm2(self.conv2(x))))\n","    x = self.pool(F.relu(self.norm3(self.conv3(x))))\n","    x = F.relu(self.norm4(self.conv4(x)))\n","    x = x.permute(0, 3, 2, 1)\n","    batch_size = x.shape[0]\n","    x = x.reshape(batch_size, -1, self.rnn_input_size)\n","\n","    # RNN\n","    # Set an initial hidden state\n","    if use_cuda and torch.cuda.is_available():\n","      h0 = torch.zeros(6, x.size(0), self.rnn_hid_units).cuda()\n","      c0 = torch.zeros(6, x.size(0), self.rnn_hid_units).cuda()\n","    else:\n","      h0 = torch.zeros(6, x.size(0), self.rnn_hid_units)\n","      c0 = torch.zeros(6, x.size(0), self.rnn_hid_units)\n","    # Forward propagate the LSTM\n","    out, _ = self.lstm(x, (h0, c0))\n","    if use_cuda and torch.cuda.is_available():\n","      del h0, c0\n","      torch.cuda.empty_cache()\n","    out = torch.stack([self.fc1(out[i]) for i in range(out.shape[0])])\n","    return out"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tAhf7042GkrG"},"source":["##Training"]},{"cell_type":"code","metadata":{"id":"QSClmHDFp5Ii"},"source":["#split labels\n","training_labels = int_label[:1638]\n","validation_labels = int_label[1638:1843]\n","testing_labels = int_label[1843:]\n","\n","#transform tensors to labels\n","\n","training_labels_tensor = torch.FloatTensor(training_labels)\n","validation_labels_tensor = torch.FloatTensor(validation_labels)\n","testing_labels_tensor = torch.FloatTensor(testing_labels)\n","\n","#split tensor data\n","training_tensor= image_tensors_list_tensor[:1638]\n","validation_tensor = image_tensors_list_tensor[1638:1843]\n","testing_tensor = image_tensors_list_tensor[1843:]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"POKN8g7Tp-8w","executionInfo":{"status":"ok","timestamp":1616973044401,"user_tz":240,"elapsed":106772,"user":{"displayName":"Mirza N","photoUrl":"","userId":"15555699542914153836"}},"outputId":"8f5db5d0-1dc4-4383-a0e4-9315eb1dae60"},"source":["print(len(int_label))\n","print(len(training_labels))\n","print(len(validation_labels))\n","print(len(testing_labels))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2048\n","1638\n","205\n","205\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Azn0F1BjVmLq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616973044803,"user_tz":240,"elapsed":107149,"user":{"displayName":"Mirza N","photoUrl":"","userId":"15555699542914153836"}},"outputId":"953df146-1fc3-41a3-87f2-89c3abf5cdeb"},"source":["max(map(max, int_label))"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["90"]},"metadata":{"tags":[]},"execution_count":26}]},{"cell_type":"code","metadata":{"id":"IdO66x9Dpvpc"},"source":["batch_size = 64\n","#\"Final\" datasets and dataloaders\n","training_dataset = TensorDataset(training_tensor,training_labels_tensor) # training dataset\n","training_loader = DataLoader(training_dataset,batch_size=batch_size, shuffle=True, drop_last=True) # create your dataloader\n","validation_dataset = TensorDataset(validation_tensor,validation_labels_tensor) # training dataset\n","validation_loader = DataLoader(validation_dataset,batch_size=batch_size, shuffle=True, drop_last=True) # create your dataloader\n","testing_dataset = TensorDataset(testing_tensor,testing_labels_tensor) # training dataset\n","testing_loader = DataLoader(testing_dataset,batch_size=batch_size, shuffle=True, drop_last=True) # create your dataloader"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ODyIPUUtqq0C"},"source":["blank_label = 91"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Pc-nH4MspeqJ"},"source":["from itertools import groupby"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vkRYJ7UtG_wr"},"source":["def get_batch_accuracy(out, labels, num_correct, num_total, batch_size=32, all=False):\n","    _, max_index = torch.max(out, dim=2)\n","    for i in range(batch_size):\n","      raw_prediction = list(max_index[:, i].detach().cpu().numpy())\n","      prediction = torch.IntTensor([c for c, _ in groupby(raw_prediction) if c != blank_label and c != 0])\n","      if use_cuda and torch.cuda.is_available():\n","        prediction = prediction.cuda()\n","      curr_label = labels[i]\n","      correct_label = curr_label[curr_label.nonzero().squeeze()] # remove zero padding\n","      if all:\n","        if len(prediction) == len(correct_label) and torch.all(prediction.eq(correct_label)):\n","          num_correct += 1\n","      else:\n","        correct_notes = 0\n","        if len(prediction) < len(correct_label):\n","          num_notes = len(prediction)\n","        else:\n","          num_notes = len(correct_label)\n","        for j in range(num_notes):\n","          if prediction[j] == correct_label[j]:\n","            correct_notes += 1\n","        num_correct += correct_notes / len(correct_label)\n","      \n","      num_total += 1\n","      del prediction\n","    return num_correct, num_total"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ojaK9gviLRuw"},"source":["def get_accuracy(model, data_loader):\n","  correct = 0\n","  total = 0\n","  for imgs, labels in iter(data_loader):\n","    out_lengths = torch.IntTensor(batch_size).fill_(model.cnn_output_width)\n","    labels_lengths = torch.IntTensor([len(t) for t in labels])\n","\n","    #############################################\n","    #To Enable GPU Usage\n","    if use_cuda and torch.cuda.is_available():\n","      imgs = imgs.cuda()\n","      labels = labels.cuda()\n","      out_lengths = out_lengths.cuda()\n","      labels_lengths = labels_lengths.cuda()\n","    #############################################\n","            \n","    out = model(imgs)             # forward pass\n","    out = out.permute(1, 0, 2)\n","    out = F.log_softmax(out, dim=-1)\n","\n","    correct, total = get_batch_accuracy(out, labels, correct, total, batch_size)\n","    del imgs, labels\n","    torch.cuda.empty_cache()\n","    \n","  return correct / total"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZPVk9hucR0if"},"source":["def train_primary(model, training_loader, validation_loader, batch_size=32, num_epochs=1, lr=0.001, plot=False, save=False):\n","    #To use batch sizes we need to set them and prepare a DataLoader for each of the sets\n","\n","    criterion = nn.CTCLoss(blank_label, zero_infinity=True)\n","    optimizer = optim.Adam(model.parameters(), lr=lr) \n","    train_acc, val_acc, train_loss, val_loss  = [], [], [], []\n","    iterations = 0\n","    plot_epochs = 0\n","    best_val = 0\n","\n","    for epoch in range(num_epochs):\n","        train_correct = 0\n","        train_total = 0\n","        val_correct = 0\n","        val_total = 0\n","        for imgs, labels in iter(training_loader):\n","            out_lengths = torch.IntTensor(batch_size).fill_(model.cnn_output_width)\n","            labels_lengths = torch.IntTensor([len(t) for t in labels])\n","\n","            #############################################\n","            #To Enable GPU Usage\n","            if use_cuda and torch.cuda.is_available():\n","              imgs = imgs.cuda()\n","              labels = labels.cuda()\n","              out_lengths = out_lengths.cuda()\n","              labels_lengths = labels_lengths.cuda()\n","            #############################################\n","            \n","            optimizer.zero_grad()         # a clean up step for PyTorch  \n","            out = model(imgs)             # forward pass\n","            out = out.permute(1, 0, 2)\n","            out = F.log_softmax(out, dim=-1)\n","            tr_loss = criterion(out, labels, out_lengths, labels_lengths)\n","            tr_loss.backward()               # backward pass (compute parameter updates)\n","            optimizer.step()              # make the updates for each parameter\n","            iterations =iterations+1\n","            \n","            train_correct, train_total = get_batch_accuracy(out, labels, train_correct, train_total, batch_size)\n","            del imgs, labels\n","            torch.cuda.empty_cache()\n","            \n","        for imgs, labels in iter(validation_loader):\n","            out_lengths = torch.IntTensor(batch_size).fill_(model.cnn_output_width)\n","            labels_lengths = torch.IntTensor([len(t) for t in labels])\n","            #############################################\n","            #To Enable GPU Usage\n","            if use_cuda and torch.cuda.is_available():\n","              imgs = imgs.cuda()\n","              labels = labels.cuda()\n","              out_lengths = out_lengths.cuda()\n","              labels_lengths = labels_lengths.cuda()\n","            #############################################\n","\n","            out = model(imgs)             # forward pass\n","            out = out.permute(1, 0, 2)\n","            out = F.log_softmax(out, dim=-1)\n","            vl_loss = criterion(out, labels, out_lengths, labels_lengths)\n","\n","            val_correct, val_total = get_batch_accuracy(out, labels, val_correct, val_total, batch_size)\n","            del imgs, labels\n","            torch.cuda.empty_cache()\n","\n","        plot_epochs = plot_epochs +1\n","        # save the current training information\n","        val_loss.append(float(vl_loss))\n","        train_loss.append(float(tr_loss))\n","        train_acc.append(train_correct / train_total) # compute training accuracy\n","        val_acc.append(val_correct / val_total)  # compute validation accuracy\n","        print(\"Epoch \", epoch+1, \"TrAcc: \",train_acc[epoch],\"ValAcc: \",val_acc[epoch],\"TrLoss: \",train_loss[epoch], \"ValLoss: \",val_loss[epoch], \"\\n\")\n","\n","        if (val_correct / val_total) >= best_val:\n","          # Save the current model (checkpoint) to a file\n","          model_path = \"bestmodel_{0}_bs{1}_lr{2}\".format(model.name, batch_size, lr)\n","          torch.save(model.state_dict(), \"/content/\" + model_path)\n","        if save:\n","          model_path = \"model_{0}_bs{1}_lr{2}_epoch{3}\".format(model.name, batch_size, lr, epoch+1)\n","          torch.save(model.state_dict(), \"/content/\" + model_path)\n","\n","    # plotting\n","    \n","    plot_epochs_l = np.arange(1, plot_epochs + 1)\n","    if (plot):\n","\n","      print(\"Epochs: {0}, Iterations: {1}, Batch Size: {2}, Learning Rate: {3}\".format(plot_epochs, iterations, batch_size, lr))\n","      plt.title(\"Training Curve; Accuracy\")\n","      plt.plot(plot_epochs_l, train_acc, label=\"Train\")\n","      plt.plot(plot_epochs_l, val_acc, label=\"Validation\")\n","      plt.xlabel(\"Epochs\")\n","      plt.ylabel(\"Accuracy\")\n","      plt.legend(loc='best')\n","      plt.show()  \n","      plt.title(\"Training Curve; Loss\")\n","      plt.plot(plot_epochs_l, train_loss, label=\"Train\")\n","      plt.plot(plot_epochs_l, val_loss, label=\"Validation\")\n","      plt.xlabel(\"Epochs\")\n","      plt.ylabel(\"Loss\")\n","      plt.legend(loc='best')\n","      plt.show()\n","\n","    print(\"Final Training Accuracy: {}\".format(train_acc[-1]))\n","    print(\"Final Validation Accuracy: {}\".format(val_acc[-1]))\n","    print(\"Final Training Loss: {}\".format(train_loss[-1]))\n","    print(\"Final Validation Loss: {}\".format(val_loss[-1]))\n","\n","    print(\"Final Epochs: {}\".format(plot_epochs))\n","    print(\"Final Iterations: {}\".format(iterations))\n","\n","    return"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wQt0cBGoD9Cb"},"source":["\n","```\n","# from https://medium.com/swlh/multi-digit-sequence-recognition-with-crnn-and-ctc-loss-using-pytorch-framework-269a7aca2a6\n","    for i in range(batch_size):\n","            raw_prediction = list(max_index[:, i].detach().numpy())  # len(raw_prediction) == 32\n","            prediction = torch.IntTensor([c for c, _ in groupby(raw_prediction) if c != blank_label])\n","            if len(prediction) == len(y_train[i]) and torch.all(prediction.eq(y_train[i])):\n","                train_correct += 1\n","            train_total += 1\n","    train_acc.append(train_correct / train_total)\n","    print('TRAINING. Correct: ', train_correct, '/', train_total, '=', train_correct / train_total)\n","```"]},{"cell_type":"markdown","metadata":{"id":"2pe23q98Grtj"},"source":["## Overfitting on Very Small Dataset"]},{"cell_type":"code","metadata":{"id":"e2gK89yxXdMc"},"source":["#Small loader for overfitting\n","psmall_labels = int_label[:1]\n","psmall_labels_tensor = torch.FloatTensor(psmall_labels)\n","psmall_tensor= image_tensors_list_tensor[:1]\n","psmall_dataset = TensorDataset(psmall_tensor, psmall_labels_tensor) # training dataset\n","psmall_loader = DataLoader(psmall_dataset, batch_size=1, shuffle=True) # create your dataloader"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"X2pjyws8oZU7"},"source":["use_cuda = True\n","model_pri_s = MusicSheetCRNN(number_of_classes=92, batch_size=1)\n","\n","if use_cuda and torch.cuda.is_available():\n","  model_pri_s.cuda()\n","  print('CUDA is available!  Training on GPU ...')\n","else:\n","  print('CUDA is not available.  Training on CPU ...')\n","\n","train_primary(model_pri_s, psmall_loader, psmall_loader, 1, num_epochs=10, lr = 0.001, plot=True, save=False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mMlaL5o9G9FY"},"source":["## Training Primary Model on Full Dataset"]},{"cell_type":"code","metadata":{"id":"23l8-K0CpOMB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616976329668,"user_tz":240,"elapsed":466,"user":{"displayName":"Mirza N","photoUrl":"","userId":"15555699542914153836"}},"outputId":"d6775a10-bd27-4dbb-a392-6cc258ac406a"},"source":["use_cuda = True\n","model_pri = MusicSheetCRNN(number_of_classes=92, batch_size=64)\n","\n","if use_cuda and torch.cuda.is_available():\n","  model_pri.cuda()\n","  print('CUDA is available!  Training on GPU ...')\n","else:\n","  print('CUDA is not available.  Training on CPU ...')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["CUDA is available!  Training on GPU ...\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"55GnD-3-JOFm","executionInfo":{"status":"ok","timestamp":1616980749347,"user_tz":240,"elapsed":3750021,"user":{"displayName":"Mirza N","photoUrl":"","userId":"15555699542914153836"}},"outputId":"34f6ad0b-a817-4444-d466-46456fb1b50d"},"source":["train_primary(model_pri, training_loader, validation_loader, 64, num_epochs=500, lr = 0.001, plot=True, save=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch  1 TrAcc:  0.0 ValAcc:  0.0 TrLoss:  1.0412285327911377 ValLoss:  1.0979083776474 \n","\n","Epoch  2 TrAcc:  0.0 ValAcc:  0.0 TrLoss:  1.0184451341629028 ValLoss:  1.0998151302337646 \n","\n","Epoch  3 TrAcc:  0.0 ValAcc:  0.0 TrLoss:  1.006742238998413 ValLoss:  1.07181978225708 \n","\n","Epoch  4 TrAcc:  0.0 ValAcc:  0.0 TrLoss:  0.9798440933227539 ValLoss:  1.1080273389816284 \n","\n","Epoch  5 TrAcc:  0.0 ValAcc:  0.0 TrLoss:  1.040299654006958 ValLoss:  1.0915113687515259 \n","\n","Epoch  6 TrAcc:  0.0 ValAcc:  0.0 TrLoss:  1.0845208168029785 ValLoss:  1.0374120473861694 \n","\n","Epoch  7 TrAcc:  0.0 ValAcc:  0.0 TrLoss:  1.0525785684585571 ValLoss:  1.046262264251709 \n","\n","Epoch  8 TrAcc:  0.0 ValAcc:  0.0 TrLoss:  1.04464852809906 ValLoss:  0.9965578317642212 \n","\n","Epoch  9 TrAcc:  0.0 ValAcc:  0.0 TrLoss:  1.0111713409423828 ValLoss:  1.077646255493164 \n","\n","Epoch  10 TrAcc:  0.0 ValAcc:  0.0 TrLoss:  0.9787642955780029 ValLoss:  1.0694421529769897 \n","\n","Epoch  11 TrAcc:  0.0 ValAcc:  0.0 TrLoss:  1.0234055519104004 ValLoss:  1.0499355792999268 \n","\n","Epoch  12 TrAcc:  0.0 ValAcc:  0.0 TrLoss:  0.9121786952018738 ValLoss:  1.0020108222961426 \n","\n","Epoch  13 TrAcc:  0.0 ValAcc:  0.0 TrLoss:  0.9479469656944275 ValLoss:  1.0433275699615479 \n","\n","Epoch  14 TrAcc:  0.0 ValAcc:  0.0 TrLoss:  0.8845143914222717 ValLoss:  1.150503158569336 \n","\n","Epoch  15 TrAcc:  0.0 ValAcc:  0.0 TrLoss:  0.9198646545410156 ValLoss:  1.0232536792755127 \n","\n","Epoch  16 TrAcc:  0.0 ValAcc:  0.0 TrLoss:  1.0326036214828491 ValLoss:  1.018642783164978 \n","\n","Epoch  17 TrAcc:  0.0 ValAcc:  0.0 TrLoss:  0.8954161405563354 ValLoss:  1.0165988206863403 \n","\n","Epoch  18 TrAcc:  0.0 ValAcc:  0.0 TrLoss:  0.944670557975769 ValLoss:  1.0322556495666504 \n","\n","Epoch  19 TrAcc:  0.0 ValAcc:  0.0 TrLoss:  0.9459083080291748 ValLoss:  1.0205682516098022 \n","\n","Epoch  20 TrAcc:  3.676470588235294e-05 ValAcc:  0.0 TrLoss:  0.9528499245643616 ValLoss:  0.9784438014030457 \n","\n","Epoch  21 TrAcc:  4.464285714285714e-05 ValAcc:  0.0 TrLoss:  0.9490282535552979 ValLoss:  0.9389901757240295 \n","\n","Epoch  22 TrAcc:  0.0 ValAcc:  0.0 TrLoss:  0.9405421614646912 ValLoss:  0.9096712470054626 \n","\n","Epoch  23 TrAcc:  0.0 ValAcc:  0.0 TrLoss:  0.9659175872802734 ValLoss:  0.9613903164863586 \n","\n","Epoch  24 TrAcc:  0.00026623951706188553 ValAcc:  0.0 TrLoss:  0.9631123542785645 ValLoss:  0.9405887126922607 \n","\n","Epoch  25 TrAcc:  0.0005024645493395492 ValAcc:  0.007770857842815081 TrLoss:  0.9613957405090332 ValLoss:  1.0404454469680786 \n","\n","Epoch  26 TrAcc:  0.0063234477027530375 ValAcc:  0.0040494227994228 TrLoss:  0.9396110773086548 ValLoss:  0.9111292958259583 \n","\n","Epoch  27 TrAcc:  0.004082928673171511 ValAcc:  0.0023753156565656567 TrLoss:  0.9838061332702637 ValLoss:  1.0349459648132324 \n","\n","Epoch  28 TrAcc:  0.006557699854647412 ValAcc:  0.01071655219475943 TrLoss:  0.9665550589561462 ValLoss:  0.9831295013427734 \n","\n","Epoch  29 TrAcc:  0.008819104503919711 ValAcc:  0.004034955206830207 TrLoss:  0.9351488351821899 ValLoss:  0.9709175825119019 \n","\n","Epoch  30 TrAcc:  0.007394712056089759 ValAcc:  0.006738573926073926 TrLoss:  0.944594144821167 ValLoss:  0.9735230207443237 \n","\n","Epoch  31 TrAcc:  0.003561534663629282 ValAcc:  0.0 TrLoss:  0.9248944520950317 ValLoss:  0.9475076794624329 \n","\n","Epoch  32 TrAcc:  0.001663882033536639 ValAcc:  0.0020203537781662783 TrLoss:  1.0028631687164307 ValLoss:  0.9577772617340088 \n","\n","Epoch  33 TrAcc:  0.0014446241162088685 ValAcc:  0.0018150252525252527 TrLoss:  0.8798366189002991 ValLoss:  0.888616681098938 \n","\n","Epoch  34 TrAcc:  0.005206020603708294 ValAcc:  0.0007628367003367003 TrLoss:  0.8503917455673218 ValLoss:  0.9874502420425415 \n","\n","Epoch  35 TrAcc:  0.0017921113785809998 ValAcc:  0.0 TrLoss:  0.9170200824737549 ValLoss:  0.9990922212600708 \n","\n","Epoch  36 TrAcc:  0.0019726343004690533 ValAcc:  0.0 TrLoss:  0.9114306569099426 ValLoss:  0.9776449203491211 \n","\n","Epoch  37 TrAcc:  0.001754056578311609 ValAcc:  0.0 TrLoss:  0.8375707864761353 ValLoss:  0.9521768689155579 \n","\n","Epoch  38 TrAcc:  0.0026855582095278315 ValAcc:  0.006315782018907018 TrLoss:  0.9034852981567383 ValLoss:  0.9149376749992371 \n","\n","Epoch  39 TrAcc:  0.004035909373564169 ValAcc:  0.0 TrLoss:  0.8807183504104614 ValLoss:  0.9818663597106934 \n","\n","Epoch  40 TrAcc:  0.0013978046806994173 ValAcc:  0.0 TrLoss:  0.9494063258171082 ValLoss:  0.926056981086731 \n","\n","Epoch  41 TrAcc:  0.001922792074519049 ValAcc:  0.0006486568986568986 TrLoss:  0.9043459296226501 ValLoss:  0.9113759994506836 \n","\n","Epoch  42 TrAcc:  0.0017364197388868446 ValAcc:  0.0 TrLoss:  0.913863480091095 ValLoss:  0.946068525314331 \n","\n","Epoch  43 TrAcc:  0.001074207818862424 ValAcc:  0.0 TrLoss:  0.8603229522705078 ValLoss:  0.9272628426551819 \n","\n","Epoch  44 TrAcc:  0.001069521240283624 ValAcc:  0.0 TrLoss:  0.8634889125823975 ValLoss:  0.9700860977172852 \n","\n","Epoch  45 TrAcc:  0.0014906741650162702 ValAcc:  0.0 TrLoss:  0.8956238031387329 ValLoss:  0.9402198195457458 \n","\n","Epoch  46 TrAcc:  0.0014891930072851126 ValAcc:  0.0 TrLoss:  0.8629540205001831 ValLoss:  0.9027206897735596 \n","\n","Epoch  47 TrAcc:  0.0012824547528494895 ValAcc:  0.0 TrLoss:  1.2320537567138672 ValLoss:  1.132041573524475 \n","\n","Epoch  48 TrAcc:  0.006653512310487922 ValAcc:  0.007295200459262959 TrLoss:  0.9105993509292603 ValLoss:  0.952194333076477 \n","\n","Epoch  49 TrAcc:  0.004946286387438666 ValAcc:  0.000248015873015873 TrLoss:  0.8777145147323608 ValLoss:  0.9432156682014465 \n","\n","Epoch  50 TrAcc:  0.0015432705543725281 ValAcc:  0.0 TrLoss:  0.8515527248382568 ValLoss:  0.9045019149780273 \n","\n","Epoch  51 TrAcc:  0.0010747244349218032 ValAcc:  0.0 TrLoss:  0.8903651833534241 ValLoss:  0.9453748464584351 \n","\n","Epoch  52 TrAcc:  0.0010716449845948684 ValAcc:  0.000248015873015873 TrLoss:  0.8568245768547058 ValLoss:  0.9649071097373962 \n","\n","Epoch  53 TrAcc:  0.0008941185824409508 ValAcc:  0.0 TrLoss:  0.8397834300994873 ValLoss:  0.9009212851524353 \n","\n","Epoch  54 TrAcc:  0.0009033809660384406 ValAcc:  0.0 TrLoss:  0.8642642498016357 ValLoss:  0.9201809763908386 \n","\n","Epoch  55 TrAcc:  0.0007316139586663801 ValAcc:  0.0 TrLoss:  0.877250611782074 ValLoss:  0.9670229554176331 \n","\n","Epoch  56 TrAcc:  0.0009868201853506264 ValAcc:  0.0 TrLoss:  0.7974380254745483 ValLoss:  0.898470401763916 \n","\n","Epoch  57 TrAcc:  0.0009853198109514598 ValAcc:  0.0 TrLoss:  0.8898271918296814 ValLoss:  0.9049345850944519 \n","\n","Epoch  58 TrAcc:  0.0011585301855268218 ValAcc:  0.0 TrLoss:  0.8288581967353821 ValLoss:  0.9428472518920898 \n","\n","Epoch  59 TrAcc:  0.0012511873042038214 ValAcc:  0.0 TrLoss:  0.8640451431274414 ValLoss:  0.8827124834060669 \n","\n","Epoch  60 TrAcc:  0.001395031178552727 ValAcc:  0.0 TrLoss:  0.8415771722793579 ValLoss:  0.8090660572052002 \n","\n","Epoch  61 TrAcc:  0.0011606670331736821 ValAcc:  0.0 TrLoss:  0.8107844591140747 ValLoss:  0.8416670560836792 \n","\n","Epoch  62 TrAcc:  0.0014950525550592039 ValAcc:  0.0 TrLoss:  0.8201479911804199 ValLoss:  0.8506622314453125 \n","\n","Epoch  63 TrAcc:  0.0028144920550085715 ValAcc:  0.0 TrLoss:  0.8040383458137512 ValLoss:  0.8464161157608032 \n","\n","Epoch  64 TrAcc:  0.0026645620629352352 ValAcc:  0.0 TrLoss:  0.7457127571105957 ValLoss:  0.8083113431930542 \n","\n","Epoch  65 TrAcc:  0.0021122282871609225 ValAcc:  0.0008680555555555555 TrLoss:  0.7226476669311523 ValLoss:  0.7895299196243286 \n","\n","Epoch  66 TrAcc:  0.003940767034521151 ValAcc:  0.0020537405303030303 TrLoss:  0.709580659866333 ValLoss:  0.8065072298049927 \n","\n","Epoch  67 TrAcc:  0.005054419758776251 ValAcc:  0.0019443682992202728 TrLoss:  0.7991520166397095 ValLoss:  0.8029394149780273 \n","\n","Epoch  68 TrAcc:  0.008820320487089904 ValAcc:  0.0018106506642512077 TrLoss:  0.7743962407112122 ValLoss:  0.8288816809654236 \n","\n","Epoch  69 TrAcc:  0.008315701915732722 ValAcc:  0.0016276041666666667 TrLoss:  0.7109327912330627 ValLoss:  0.8453871607780457 \n","\n","Epoch  70 TrAcc:  0.008114871676270667 ValAcc:  0.0027752214738234475 TrLoss:  0.7357504367828369 ValLoss:  0.8218644857406616 \n","\n","Epoch  71 TrAcc:  0.008024949366230195 ValAcc:  0.008449699049302376 TrLoss:  0.7744894027709961 ValLoss:  0.75160813331604 \n","\n","Epoch  72 TrAcc:  0.010985502674001755 ValAcc:  0.015511011885976133 TrLoss:  0.7359864711761475 ValLoss:  0.7962895631790161 \n","\n","Epoch  73 TrAcc:  0.013078505748027047 ValAcc:  0.009502921000961829 TrLoss:  0.758690595626831 ValLoss:  0.7839736938476562 \n","\n","Epoch  74 TrAcc:  0.02037318528577871 ValAcc:  0.016788730031800897 TrLoss:  0.7344633340835571 ValLoss:  0.8075873851776123 \n","\n","Epoch  75 TrAcc:  0.0200952824057425 ValAcc:  0.013028621814818642 TrLoss:  0.7116893529891968 ValLoss:  0.7767621278762817 \n","\n","Epoch  76 TrAcc:  0.021193281406043946 ValAcc:  0.02142519029003793 TrLoss:  0.693240761756897 ValLoss:  0.7955373525619507 \n","\n","Epoch  77 TrAcc:  0.025714704367724498 ValAcc:  0.012762291838457665 TrLoss:  0.7108938694000244 ValLoss:  0.7825859785079956 \n","\n","Epoch  78 TrAcc:  0.03215076461495045 ValAcc:  0.02605876046084499 TrLoss:  0.6829589605331421 ValLoss:  0.8346585035324097 \n","\n","Epoch  79 TrAcc:  0.032341437501551155 ValAcc:  0.027678781061738673 TrLoss:  0.7335141897201538 ValLoss:  0.7714849710464478 \n","\n","Epoch  80 TrAcc:  0.0415119825970081 ValAcc:  0.024381096784021557 TrLoss:  0.6742767095565796 ValLoss:  0.7256668210029602 \n","\n","Epoch  81 TrAcc:  0.049490089965913364 ValAcc:  0.02740744085448958 TrLoss:  0.674367368221283 ValLoss:  0.7662182450294495 \n","\n","Epoch  82 TrAcc:  0.052052175248094586 ValAcc:  0.048792727409166146 TrLoss:  0.6584452390670776 ValLoss:  0.7887885570526123 \n","\n","Epoch  83 TrAcc:  0.06523157613126916 ValAcc:  0.06815279718401142 TrLoss:  0.6692352294921875 ValLoss:  0.7234153151512146 \n","\n","Epoch  84 TrAcc:  0.07391667877150848 ValAcc:  0.06307426534943907 TrLoss:  0.6783568859100342 ValLoss:  0.7051912546157837 \n","\n","Epoch  85 TrAcc:  0.078270906176059 ValAcc:  0.06577405062198079 TrLoss:  0.7028239965438843 ValLoss:  0.7402065992355347 \n","\n","Epoch  86 TrAcc:  0.08031479487584056 ValAcc:  0.0730877143715713 TrLoss:  0.6275894641876221 ValLoss:  0.7752225399017334 \n","\n","Epoch  87 TrAcc:  0.09034430414829328 ValAcc:  0.09230290372773059 TrLoss:  0.6877260804176331 ValLoss:  0.7409517765045166 \n","\n","Epoch  88 TrAcc:  0.09744355797799871 ValAcc:  0.07363930224832703 TrLoss:  0.6891108155250549 ValLoss:  0.7742319107055664 \n","\n","Epoch  89 TrAcc:  0.10608374128169185 ValAcc:  0.0959547106074124 TrLoss:  0.6874908804893494 ValLoss:  0.8031723499298096 \n","\n","Epoch  90 TrAcc:  0.10570166080643005 ValAcc:  0.08380428552097431 TrLoss:  0.6384353637695312 ValLoss:  0.7515841722488403 \n","\n","Epoch  91 TrAcc:  0.11372806840354484 ValAcc:  0.11403647047541009 TrLoss:  0.6047320365905762 ValLoss:  0.7306675910949707 \n","\n","Epoch  92 TrAcc:  0.12966109869246978 ValAcc:  0.07673974293350215 TrLoss:  0.6244301795959473 ValLoss:  0.8090661764144897 \n","\n","Epoch  93 TrAcc:  0.12642279948301702 ValAcc:  0.11993169707089084 TrLoss:  0.5886291861534119 ValLoss:  0.7643353939056396 \n","\n","Epoch  94 TrAcc:  0.13645076634659795 ValAcc:  0.10523453326878356 TrLoss:  0.651746392250061 ValLoss:  0.7476791739463806 \n","\n","Epoch  95 TrAcc:  0.1384058631301856 ValAcc:  0.09567753454774018 TrLoss:  0.6285076141357422 ValLoss:  0.8239999413490295 \n","\n","Epoch  96 TrAcc:  0.15008016244172714 ValAcc:  0.10029278368726702 TrLoss:  0.5943716764450073 ValLoss:  0.6766846179962158 \n","\n","Epoch  97 TrAcc:  0.15242856952607503 ValAcc:  0.13214728843864343 TrLoss:  0.6389633417129517 ValLoss:  0.7654851675033569 \n","\n","Epoch  98 TrAcc:  0.16163147795744479 ValAcc:  0.10619372393970354 TrLoss:  0.6147425770759583 ValLoss:  0.8055585622787476 \n","\n","Epoch  99 TrAcc:  0.16618691461705187 ValAcc:  0.10938785932626054 TrLoss:  0.6257275938987732 ValLoss:  0.8082040548324585 \n","\n","Epoch  100 TrAcc:  0.17259411763022253 ValAcc:  0.12885692161091986 TrLoss:  0.5850961208343506 ValLoss:  0.7761838436126709 \n","\n","Epoch  101 TrAcc:  0.1802162420744736 ValAcc:  0.13793314214507227 TrLoss:  0.6058216094970703 ValLoss:  0.7541236877441406 \n","\n","Epoch  102 TrAcc:  0.18660879586485468 ValAcc:  0.1258116309825878 TrLoss:  0.5495465993881226 ValLoss:  0.7934409379959106 \n","\n","Epoch  103 TrAcc:  0.19345842924103887 ValAcc:  0.1374318415304962 TrLoss:  0.6033058166503906 ValLoss:  0.749341607093811 \n","\n","Epoch  104 TrAcc:  0.20096455036948696 ValAcc:  0.13588760272083758 TrLoss:  0.5929150581359863 ValLoss:  0.7816857099533081 \n","\n","Epoch  105 TrAcc:  0.209227000240588 ValAcc:  0.1371957436402043 TrLoss:  0.5962732434272766 ValLoss:  0.8161804676055908 \n","\n","Epoch  106 TrAcc:  0.217817249229681 ValAcc:  0.15472950507436875 TrLoss:  0.5854794383049011 ValLoss:  0.8180185556411743 \n","\n","Epoch  107 TrAcc:  0.22103027898913805 ValAcc:  0.15227079848482775 TrLoss:  0.584830641746521 ValLoss:  0.7514356374740601 \n","\n","Epoch  108 TrAcc:  0.21100484531000838 ValAcc:  0.151034950543538 TrLoss:  0.5593013167381287 ValLoss:  0.76697838306427 \n","\n","Epoch  109 TrAcc:  0.2268898300071156 ValAcc:  0.15922026608413473 TrLoss:  0.5838857889175415 ValLoss:  0.7945418357849121 \n","\n","Epoch  110 TrAcc:  0.20822536327584173 ValAcc:  0.1451609935384616 TrLoss:  0.5307929515838623 ValLoss:  0.7288697361946106 \n","\n","Epoch  111 TrAcc:  0.22799806687272817 ValAcc:  0.14840114438741855 TrLoss:  0.5777642726898193 ValLoss:  0.845126748085022 \n","\n","Epoch  112 TrAcc:  0.23539067540697278 ValAcc:  0.16441421666435643 TrLoss:  0.5964409112930298 ValLoss:  0.7110479474067688 \n","\n","Epoch  113 TrAcc:  0.2527306438855266 ValAcc:  0.1503907410570172 TrLoss:  0.5372890830039978 ValLoss:  0.8215856552124023 \n","\n","Epoch  114 TrAcc:  0.25272783680402655 ValAcc:  0.16629964906356398 TrLoss:  0.5305124521255493 ValLoss:  0.8197419047355652 \n","\n","Epoch  115 TrAcc:  0.25828342440721885 ValAcc:  0.1600723386588692 TrLoss:  0.5254185199737549 ValLoss:  0.7934185862541199 \n","\n","Epoch  116 TrAcc:  0.2636610122746135 ValAcc:  0.15670202934876215 TrLoss:  0.5102992653846741 ValLoss:  0.8255398273468018 \n","\n","Epoch  117 TrAcc:  0.2694425062411907 ValAcc:  0.16890458059877522 TrLoss:  0.49477970600128174 ValLoss:  0.8154504299163818 \n","\n","Epoch  118 TrAcc:  0.2660841576466668 ValAcc:  0.1669286533259855 TrLoss:  0.5073358416557312 ValLoss:  0.8378661870956421 \n","\n","Epoch  119 TrAcc:  0.2741663393008393 ValAcc:  0.17489526791830778 TrLoss:  0.5336108803749084 ValLoss:  0.8135215044021606 \n","\n","Epoch  120 TrAcc:  0.28496961408251426 ValAcc:  0.16323664223544546 TrLoss:  0.5384324789047241 ValLoss:  0.7705617547035217 \n","\n","Epoch  121 TrAcc:  0.2911129288235179 ValAcc:  0.15697843743661863 TrLoss:  0.5256822109222412 ValLoss:  0.9528836011886597 \n","\n","Epoch  122 TrAcc:  0.2934663764614644 ValAcc:  0.17640320476048174 TrLoss:  0.4884909987449646 ValLoss:  0.8147647380828857 \n","\n","Epoch  123 TrAcc:  0.300288683694988 ValAcc:  0.16543596068177724 TrLoss:  0.48319801688194275 ValLoss:  0.8426542282104492 \n","\n","Epoch  124 TrAcc:  0.30175117795693857 ValAcc:  0.1650411757785573 TrLoss:  0.5113973021507263 ValLoss:  0.8106454014778137 \n","\n","Epoch  125 TrAcc:  0.3081002074057238 ValAcc:  0.1784552298185 TrLoss:  0.5087268948554993 ValLoss:  0.8683489561080933 \n","\n","Epoch  126 TrAcc:  0.31403004216801245 ValAcc:  0.16840763943704587 TrLoss:  0.459506094455719 ValLoss:  0.8283261060714722 \n","\n","Epoch  127 TrAcc:  0.3210636976303453 ValAcc:  0.1604282721541889 TrLoss:  0.4653683602809906 ValLoss:  0.8319149017333984 \n","\n","Epoch  128 TrAcc:  0.3236999538551794 ValAcc:  0.1820572391836189 TrLoss:  0.4509068727493286 ValLoss:  0.900163471698761 \n","\n","Epoch  129 TrAcc:  0.3272669478833589 ValAcc:  0.17147163765870324 TrLoss:  0.5140380263328552 ValLoss:  0.8440393209457397 \n","\n","Epoch  130 TrAcc:  0.32738525263083235 ValAcc:  0.17512173869653322 TrLoss:  0.4654015302658081 ValLoss:  0.8210453987121582 \n","\n","Epoch  131 TrAcc:  0.3353368966684791 ValAcc:  0.17082871451949233 TrLoss:  0.43000513315200806 ValLoss:  0.8151211738586426 \n","\n","Epoch  132 TrAcc:  0.339111825623973 ValAcc:  0.16833564925895225 TrLoss:  0.5207058191299438 ValLoss:  0.915454089641571 \n","\n","Epoch  133 TrAcc:  0.3456859045700918 ValAcc:  0.17511004036339717 TrLoss:  0.45876187086105347 ValLoss:  0.8580234050750732 \n","\n","Epoch  134 TrAcc:  0.35117382336548686 ValAcc:  0.18006069984235684 TrLoss:  0.43857675790786743 ValLoss:  0.8686667084693909 \n","\n","Epoch  135 TrAcc:  0.3532199838379769 ValAcc:  0.1695948900504106 TrLoss:  0.4345877170562744 ValLoss:  0.8420538902282715 \n","\n","Epoch  136 TrAcc:  0.34800424933749674 ValAcc:  0.17248885481296572 TrLoss:  0.4716571569442749 ValLoss:  0.9012587070465088 \n","\n","Epoch  137 TrAcc:  0.34834798892302915 ValAcc:  0.16943404179197294 TrLoss:  0.4397595524787903 ValLoss:  0.8563761711120605 \n","\n","Epoch  138 TrAcc:  0.3526667340905536 ValAcc:  0.1702903240113727 TrLoss:  0.4433877766132355 ValLoss:  0.7965360879898071 \n","\n","Epoch  139 TrAcc:  0.3516774511595714 ValAcc:  0.18747706966819253 TrLoss:  0.4512196183204651 ValLoss:  0.9661908149719238 \n","\n","Epoch  140 TrAcc:  0.36033408607781764 ValAcc:  0.1769134572994446 TrLoss:  0.4443114101886749 ValLoss:  0.9247444868087769 \n","\n","Epoch  141 TrAcc:  0.37075292881306376 ValAcc:  0.17738690929617099 TrLoss:  0.42282092571258545 ValLoss:  0.9994688034057617 \n","\n","Epoch  142 TrAcc:  0.38000668609584864 ValAcc:  0.17200590513476977 TrLoss:  0.4440184533596039 ValLoss:  0.8582034111022949 \n","\n","Epoch  143 TrAcc:  0.3625995625208761 ValAcc:  0.17946248805715825 TrLoss:  0.465009868144989 ValLoss:  0.9271944761276245 \n","\n","Epoch  144 TrAcc:  0.3493956815933516 ValAcc:  0.18499107665193493 TrLoss:  0.502906084060669 ValLoss:  0.8890918493270874 \n","\n","Epoch  145 TrAcc:  0.358627576753516 ValAcc:  0.15854759709659008 TrLoss:  0.4717259109020233 ValLoss:  0.9646669030189514 \n","\n","Epoch  146 TrAcc:  0.36582338632461725 ValAcc:  0.1714394179807488 TrLoss:  0.43706774711608887 ValLoss:  0.8553471565246582 \n","\n","Epoch  147 TrAcc:  0.3851915267602874 ValAcc:  0.19093955744924496 TrLoss:  0.43859291076660156 ValLoss:  0.9422709345817566 \n","\n","Epoch  148 TrAcc:  0.3991921697073603 ValAcc:  0.1875623643113431 TrLoss:  0.40201687812805176 ValLoss:  0.8593666553497314 \n","\n","Epoch  149 TrAcc:  0.39500033896712095 ValAcc:  0.1857148621832684 TrLoss:  0.4158887267112732 ValLoss:  0.922831654548645 \n","\n","Epoch  150 TrAcc:  0.40042362612472976 ValAcc:  0.18462447701848925 TrLoss:  0.4090583920478821 ValLoss:  0.9784718751907349 \n","\n","Epoch  151 TrAcc:  0.40705187819271743 ValAcc:  0.18449455026748718 TrLoss:  0.4163668751716614 ValLoss:  0.9283757209777832 \n","\n","Epoch  152 TrAcc:  0.4227272290734046 ValAcc:  0.19521009721945246 TrLoss:  0.37524887919425964 ValLoss:  0.9460694193840027 \n","\n","Epoch  153 TrAcc:  0.4122869026965736 ValAcc:  0.1736385781830049 TrLoss:  0.3796251714229584 ValLoss:  0.9032471776008606 \n","\n","Epoch  154 TrAcc:  0.42193866833852134 ValAcc:  0.20698345589211933 TrLoss:  0.41285157203674316 ValLoss:  0.9812377691268921 \n","\n","Epoch  155 TrAcc:  0.4268631705014087 ValAcc:  0.18587581977331505 TrLoss:  0.3605169355869293 ValLoss:  0.998733639717102 \n","\n","Epoch  156 TrAcc:  0.4257748104857896 ValAcc:  0.19302862653888822 TrLoss:  0.3910835385322571 ValLoss:  0.9376949071884155 \n","\n","Epoch  157 TrAcc:  0.43131994175560384 ValAcc:  0.1878833264655454 TrLoss:  0.361177533864975 ValLoss:  0.9508661031723022 \n","\n","Epoch  158 TrAcc:  0.4418317082684976 ValAcc:  0.19259631411724876 TrLoss:  0.36648839712142944 ValLoss:  0.919670820236206 \n","\n","Epoch  159 TrAcc:  0.437661294185537 ValAcc:  0.18577374385394999 TrLoss:  0.3510189950466156 ValLoss:  1.0216600894927979 \n","\n","Epoch  160 TrAcc:  0.43228527507470865 ValAcc:  0.18664655246964648 TrLoss:  0.39492297172546387 ValLoss:  1.1050608158111572 \n","\n","Epoch  161 TrAcc:  0.42774607364841977 ValAcc:  0.19731644253714645 TrLoss:  0.3365137577056885 ValLoss:  1.14339017868042 \n","\n","Epoch  162 TrAcc:  0.44071876682707656 ValAcc:  0.18549596846213676 TrLoss:  0.3857187032699585 ValLoss:  0.9650115966796875 \n","\n","Epoch  163 TrAcc:  0.4555950047738506 ValAcc:  0.19934324698063086 TrLoss:  0.3536202609539032 ValLoss:  0.938875675201416 \n","\n","Epoch  164 TrAcc:  0.46565783343049544 ValAcc:  0.19497765260966793 TrLoss:  0.34615325927734375 ValLoss:  1.0501720905303955 \n","\n","Epoch  165 TrAcc:  0.4769996739780915 ValAcc:  0.18979095342787244 TrLoss:  0.35527753829956055 ValLoss:  1.0904943943023682 \n","\n","Epoch  166 TrAcc:  0.4826911840981143 ValAcc:  0.18426185060891534 TrLoss:  0.3463417887687683 ValLoss:  1.0222079753875732 \n","\n","Epoch  167 TrAcc:  0.46924712957011055 ValAcc:  0.19350124295855328 TrLoss:  0.352838397026062 ValLoss:  1.044980525970459 \n","\n","Epoch  168 TrAcc:  0.48173394698458344 ValAcc:  0.19915956672776444 TrLoss:  0.3135959506034851 ValLoss:  1.032079815864563 \n","\n","Epoch  169 TrAcc:  0.4789941004297851 ValAcc:  0.196063323762296 TrLoss:  0.34462475776672363 ValLoss:  1.0856300592422485 \n","\n","Epoch  170 TrAcc:  0.4866428842023764 ValAcc:  0.20358231042650324 TrLoss:  0.33306923508644104 ValLoss:  1.0971510410308838 \n","\n","Epoch  171 TrAcc:  0.4943970075053092 ValAcc:  0.20239747404812103 TrLoss:  0.33596280217170715 ValLoss:  1.077465295791626 \n","\n","Epoch  172 TrAcc:  0.5012081792858628 ValAcc:  0.20015133140112115 TrLoss:  0.3169049620628357 ValLoss:  0.9959917664527893 \n","\n","Epoch  173 TrAcc:  0.5134441017407572 ValAcc:  0.1991189540556991 TrLoss:  0.29213258624076843 ValLoss:  1.0401657819747925 \n","\n","Epoch  174 TrAcc:  0.52128688636415 ValAcc:  0.2034573260171002 TrLoss:  0.3098790943622589 ValLoss:  1.072180986404419 \n","\n","Epoch  175 TrAcc:  0.5331957462127928 ValAcc:  0.20691995303272157 TrLoss:  0.2814179062843323 ValLoss:  0.9924821853637695 \n","\n","Epoch  176 TrAcc:  0.5366328237088388 ValAcc:  0.19471078602378342 TrLoss:  0.2826632559299469 ValLoss:  1.186496615409851 \n","\n","Epoch  177 TrAcc:  0.540380872385442 ValAcc:  0.19856313031960204 TrLoss:  0.3052135109901428 ValLoss:  1.0590260028839111 \n","\n","Epoch  178 TrAcc:  0.5424300787103215 ValAcc:  0.1964097243481507 TrLoss:  0.30183762311935425 ValLoss:  1.0552234649658203 \n","\n","Epoch  179 TrAcc:  0.5499111483552581 ValAcc:  0.21465762251856543 TrLoss:  0.3101380467414856 ValLoss:  1.161011815071106 \n","\n","Epoch  180 TrAcc:  0.5477601863986472 ValAcc:  0.1992990106831609 TrLoss:  0.29297468066215515 ValLoss:  1.045067548751831 \n","\n","Epoch  181 TrAcc:  0.5509084077485784 ValAcc:  0.18871728989758838 TrLoss:  0.2775094211101532 ValLoss:  1.1101114749908447 \n","\n","Epoch  182 TrAcc:  0.5554165676720052 ValAcc:  0.2014451150450959 TrLoss:  0.27457696199417114 ValLoss:  1.1416090726852417 \n","\n","Epoch  183 TrAcc:  0.5652220592841004 ValAcc:  0.20392987969313645 TrLoss:  0.2970828115940094 ValLoss:  1.1342418193817139 \n","\n","Epoch  184 TrAcc:  0.562454198957953 ValAcc:  0.20485111265335934 TrLoss:  0.2825782895088196 ValLoss:  1.1742396354675293 \n","\n","Epoch  185 TrAcc:  0.5651660906510962 ValAcc:  0.20839365262972273 TrLoss:  0.2641116976737976 ValLoss:  1.104946255683899 \n","\n","Epoch  186 TrAcc:  0.5768163162095764 ValAcc:  0.19844419517337197 TrLoss:  0.254230797290802 ValLoss:  1.1434274911880493 \n","\n","Epoch  187 TrAcc:  0.5739804851615146 ValAcc:  0.196061743716453 TrLoss:  0.30030232667922974 ValLoss:  1.0730873346328735 \n","\n","Epoch  188 TrAcc:  0.5837619211282385 ValAcc:  0.19470421939872318 TrLoss:  0.2591174840927124 ValLoss:  1.1741267442703247 \n","\n","Epoch  189 TrAcc:  0.5937572505835808 ValAcc:  0.20271009417882635 TrLoss:  0.2646442949771881 ValLoss:  1.2095376253128052 \n","\n","Epoch  190 TrAcc:  0.6018608268124077 ValAcc:  0.19825283637315141 TrLoss:  0.23363488912582397 ValLoss:  1.1002929210662842 \n","\n","Epoch  191 TrAcc:  0.6101477214999071 ValAcc:  0.19990973555350697 TrLoss:  0.23986759781837463 ValLoss:  1.1012217998504639 \n","\n","Epoch  192 TrAcc:  0.6003348810717951 ValAcc:  0.19511370177221501 TrLoss:  0.24949604272842407 ValLoss:  1.2990100383758545 \n","\n","Epoch  193 TrAcc:  0.6079709283318665 ValAcc:  0.19346007262370712 TrLoss:  0.24793322384357452 ValLoss:  1.1999809741973877 \n","\n","Epoch  194 TrAcc:  0.6105098125812076 ValAcc:  0.20259302674649735 TrLoss:  0.25698089599609375 ValLoss:  1.2381043434143066 \n","\n","Epoch  195 TrAcc:  0.5918302654262783 ValAcc:  0.20259446600603845 TrLoss:  0.2712634205818176 ValLoss:  1.233088493347168 \n","\n","Epoch  196 TrAcc:  0.5796906065500269 ValAcc:  0.1986405012592979 TrLoss:  0.2593282461166382 ValLoss:  1.2779545783996582 \n","\n","Epoch  197 TrAcc:  0.5923099888525312 ValAcc:  0.20455141435480304 TrLoss:  0.24357128143310547 ValLoss:  1.2586066722869873 \n","\n","Epoch  198 TrAcc:  0.6029867506983411 ValAcc:  0.2034677546430054 TrLoss:  0.2386779487133026 ValLoss:  1.2493274211883545 \n","\n","Epoch  199 TrAcc:  0.6167356143484775 ValAcc:  0.1935460976214064 TrLoss:  0.23700982332229614 ValLoss:  1.2026281356811523 \n","\n","Epoch  200 TrAcc:  0.6273168815075438 ValAcc:  0.2152522203206599 TrLoss:  0.23059429228305817 ValLoss:  1.3450803756713867 \n","\n","Epoch  201 TrAcc:  0.6477741561652018 ValAcc:  0.20574159595512245 TrLoss:  0.22181378304958344 ValLoss:  1.201297402381897 \n","\n","Epoch  202 TrAcc:  0.645030865786492 ValAcc:  0.2045138913032578 TrLoss:  0.23434971272945404 ValLoss:  1.1554780006408691 \n","\n","Epoch  203 TrAcc:  0.6515481066090436 ValAcc:  0.20653427406357752 TrLoss:  0.21241044998168945 ValLoss:  1.243581771850586 \n","\n","Epoch  204 TrAcc:  0.6706790727503917 ValAcc:  0.20263941274175146 TrLoss:  0.20976054668426514 ValLoss:  1.3899379968643188 \n","\n","Epoch  205 TrAcc:  0.6885714770750317 ValAcc:  0.20334027090427795 TrLoss:  0.18442487716674805 ValLoss:  1.4148292541503906 \n","\n","Epoch  206 TrAcc:  0.6957274223157244 ValAcc:  0.19470696686115666 TrLoss:  0.19115668535232544 ValLoss:  1.3746668100357056 \n","\n","Epoch  207 TrAcc:  0.6954150146614982 ValAcc:  0.20528706683988152 TrLoss:  0.21052759885787964 ValLoss:  1.3413426876068115 \n","\n","Epoch  208 TrAcc:  0.6962142215008771 ValAcc:  0.19893806942326683 TrLoss:  0.1964150220155716 ValLoss:  1.354324460029602 \n","\n","Epoch  209 TrAcc:  0.6940105663130445 ValAcc:  0.20245002877286403 TrLoss:  0.20265662670135498 ValLoss:  1.2346832752227783 \n","\n","Epoch  210 TrAcc:  0.6983127457869093 ValAcc:  0.20364107457034042 TrLoss:  0.20634733140468597 ValLoss:  1.3348088264465332 \n","\n","Epoch  211 TrAcc:  0.6864296377747136 ValAcc:  0.19298236912190678 TrLoss:  0.1886623203754425 ValLoss:  1.4133192300796509 \n","\n","Epoch  212 TrAcc:  0.6939751554915304 ValAcc:  0.1984595673387222 TrLoss:  0.18462181091308594 ValLoss:  1.2168265581130981 \n","\n","Epoch  213 TrAcc:  0.7075366469730604 ValAcc:  0.20865437085339125 TrLoss:  0.1957404762506485 ValLoss:  1.2330703735351562 \n","\n","Epoch  214 TrAcc:  0.7107851419108142 ValAcc:  0.20010403262172607 TrLoss:  0.1686694175004959 ValLoss:  1.3151214122772217 \n","\n","Epoch  215 TrAcc:  0.7266666940526426 ValAcc:  0.20874802684121532 TrLoss:  0.1635926067829132 ValLoss:  1.4525855779647827 \n","\n","Epoch  216 TrAcc:  0.7382496543611475 ValAcc:  0.20361669281065084 TrLoss:  0.1805056780576706 ValLoss:  1.294435977935791 \n","\n","Epoch  217 TrAcc:  0.7277092264325082 ValAcc:  0.2093563472795779 TrLoss:  0.18779107928276062 ValLoss:  1.4761158227920532 \n","\n","Epoch  218 TrAcc:  0.7322929824587101 ValAcc:  0.20935404790687936 TrLoss:  0.19327493011951447 ValLoss:  1.1347979307174683 \n","\n","Epoch  219 TrAcc:  0.7301107737133666 ValAcc:  0.20877106025489892 TrLoss:  0.17543283104896545 ValLoss:  1.4824397563934326 \n","\n","Epoch  220 TrAcc:  0.7383798254415842 ValAcc:  0.2056615069355313 TrLoss:  0.1801167130470276 ValLoss:  1.4356478452682495 \n","\n","Epoch  221 TrAcc:  0.7453557723491079 ValAcc:  0.19480470702973415 TrLoss:  0.15935368835926056 ValLoss:  1.1607887744903564 \n","\n","Epoch  222 TrAcc:  0.7509504326110836 ValAcc:  0.2009458634637148 TrLoss:  0.15778058767318726 ValLoss:  1.4804205894470215 \n","\n","Epoch  223 TrAcc:  0.7535728980130831 ValAcc:  0.20744917650961528 TrLoss:  0.16923585534095764 ValLoss:  1.3910586833953857 \n","\n","Epoch  224 TrAcc:  0.7489693501129224 ValAcc:  0.20267395798101065 TrLoss:  0.14808236062526703 ValLoss:  1.5131226778030396 \n","\n","Epoch  225 TrAcc:  0.756565886558536 ValAcc:  0.20763707011352447 TrLoss:  0.14129915833473206 ValLoss:  1.2929059267044067 \n","\n","Epoch  226 TrAcc:  0.7726127963260339 ValAcc:  0.21347199454412846 TrLoss:  0.1828293651342392 ValLoss:  1.4998384714126587 \n","\n","Epoch  227 TrAcc:  0.7590856744327623 ValAcc:  0.1931032128556874 TrLoss:  0.17076736688613892 ValLoss:  1.2587435245513916 \n","\n","Epoch  228 TrAcc:  0.7471923049441549 ValAcc:  0.20097777305013623 TrLoss:  0.13850843906402588 ValLoss:  1.2741034030914307 \n","\n","Epoch  229 TrAcc:  0.7859935347366043 ValAcc:  0.2018843627820641 TrLoss:  0.15109363198280334 ValLoss:  1.4194066524505615 \n","\n","Epoch  230 TrAcc:  0.7909664858231606 ValAcc:  0.1897738683439043 TrLoss:  0.14443205296993256 ValLoss:  1.3787214756011963 \n","\n","Epoch  231 TrAcc:  0.7969846685588681 ValAcc:  0.21031894994412023 TrLoss:  0.13283580541610718 ValLoss:  1.3625895977020264 \n","\n","Epoch  232 TrAcc:  0.7960173744597497 ValAcc:  0.19942551445428688 TrLoss:  0.141154944896698 ValLoss:  1.3451170921325684 \n","\n","Epoch  233 TrAcc:  0.7997573792970898 ValAcc:  0.18987082294767968 TrLoss:  0.12564946711063385 ValLoss:  1.4513840675354004 \n","\n","Epoch  234 TrAcc:  0.800538926859843 ValAcc:  0.2008265595095133 TrLoss:  0.13426265120506287 ValLoss:  1.352083444595337 \n","\n","Epoch  235 TrAcc:  0.7966036318866472 ValAcc:  0.19257142680798603 TrLoss:  0.14135006070137024 ValLoss:  1.3149787187576294 \n","\n","Epoch  236 TrAcc:  0.7888801250796031 ValAcc:  0.19943380554569076 TrLoss:  0.14294597506523132 ValLoss:  1.3342804908752441 \n","\n","Epoch  237 TrAcc:  0.799319964013478 ValAcc:  0.21149874838785077 TrLoss:  0.13260969519615173 ValLoss:  1.4041733741760254 \n","\n","Epoch  238 TrAcc:  0.8030819129401767 ValAcc:  0.20486114143371617 TrLoss:  0.1386803388595581 ValLoss:  1.5259944200515747 \n","\n","Epoch  239 TrAcc:  0.8213279605416939 ValAcc:  0.21107476517721105 TrLoss:  0.11811140179634094 ValLoss:  1.4202384948730469 \n","\n","Epoch  240 TrAcc:  0.8390562572096312 ValAcc:  0.19118600956650125 TrLoss:  0.13437500596046448 ValLoss:  1.6046864986419678 \n","\n","Epoch  241 TrAcc:  0.8075581994045108 ValAcc:  0.20682484094469641 TrLoss:  0.1286032497882843 ValLoss:  1.4345554113388062 \n","\n","Epoch  242 TrAcc:  0.8074643427659551 ValAcc:  0.20078440000386508 TrLoss:  0.12149719148874283 ValLoss:  1.5349576473236084 \n","\n","Epoch  243 TrAcc:  0.8289276460793654 ValAcc:  0.20350622996519785 TrLoss:  0.11314274370670319 ValLoss:  1.5321152210235596 \n","\n","Epoch  244 TrAcc:  0.8254999623334909 ValAcc:  0.20514576341620802 TrLoss:  0.12274813652038574 ValLoss:  1.4758248329162598 \n","\n","Epoch  245 TrAcc:  0.6872925346488821 ValAcc:  0.1986313625115953 TrLoss:  0.1862739622592926 ValLoss:  1.4463260173797607 \n","\n","Epoch  246 TrAcc:  0.6992103397360093 ValAcc:  0.2047030514014 TrLoss:  0.1494811326265335 ValLoss:  1.5399658679962158 \n","\n","Epoch  247 TrAcc:  0.7565181818933817 ValAcc:  0.18808152829033833 TrLoss:  0.17254316806793213 ValLoss:  1.5290493965148926 \n","\n","Epoch  248 TrAcc:  0.7401557168894803 ValAcc:  0.20228962227252298 TrLoss:  0.1524166464805603 ValLoss:  1.6052714586257935 \n","\n","Epoch  249 TrAcc:  0.7546611640293444 ValAcc:  0.2049990005040264 TrLoss:  0.15993665158748627 ValLoss:  1.5866608619689941 \n","\n","Epoch  250 TrAcc:  0.8012321468110224 ValAcc:  0.21279241862925202 TrLoss:  0.12252812087535858 ValLoss:  1.5045040845870972 \n","\n","Epoch  251 TrAcc:  0.8385528996751532 ValAcc:  0.20532680712266738 TrLoss:  0.10920141637325287 ValLoss:  1.5956300497055054 \n","\n","Epoch  252 TrAcc:  0.8615237069015332 ValAcc:  0.20258760168657722 TrLoss:  0.10297302901744843 ValLoss:  1.5771064758300781 \n","\n","Epoch  253 TrAcc:  0.8704032468517705 ValAcc:  0.19768709547874705 TrLoss:  0.08351655304431915 ValLoss:  1.5970878601074219 \n","\n","Epoch  254 TrAcc:  0.890550819182465 ValAcc:  0.20630076289809265 TrLoss:  0.08899727463722229 ValLoss:  1.6075419187545776 \n","\n","Epoch  255 TrAcc:  0.8932683138919013 ValAcc:  0.2013179965702175 TrLoss:  0.07789875566959381 ValLoss:  1.6906055212020874 \n","\n","Epoch  256 TrAcc:  0.904091792520389 ValAcc:  0.20848124712513846 TrLoss:  0.09229685366153717 ValLoss:  1.6827800273895264 \n","\n","Epoch  257 TrAcc:  0.9091668818774555 ValAcc:  0.1973805643177572 TrLoss:  0.08072923868894577 ValLoss:  1.6204396486282349 \n","\n","Epoch  258 TrAcc:  0.9155531655537237 ValAcc:  0.20638675656327662 TrLoss:  0.08204349130392075 ValLoss:  1.6291084289550781 \n","\n","Epoch  259 TrAcc:  0.9123245221306717 ValAcc:  0.2083376824643157 TrLoss:  0.07432421296834946 ValLoss:  1.54880690574646 \n","\n","Epoch  260 TrAcc:  0.9125347795196432 ValAcc:  0.19888600620156757 TrLoss:  0.07312873005867004 ValLoss:  1.7337640523910522 \n","\n","Epoch  261 TrAcc:  0.9138290539062395 ValAcc:  0.20942763102813663 TrLoss:  0.07091445475816727 ValLoss:  1.7199100255966187 \n","\n","Epoch  262 TrAcc:  0.8975854365690492 ValAcc:  0.19874565360886898 TrLoss:  0.09741629660129547 ValLoss:  1.713073968887329 \n","\n","Epoch  263 TrAcc:  0.8886927867323814 ValAcc:  0.20410768131178114 TrLoss:  0.0881880521774292 ValLoss:  1.6554651260375977 \n","\n","Epoch  264 TrAcc:  0.8737616913166845 ValAcc:  0.20022262958375348 TrLoss:  0.08569081127643585 ValLoss:  1.621600866317749 \n","\n","Epoch  265 TrAcc:  0.8782744195965045 ValAcc:  0.1976084135752959 TrLoss:  0.08660416305065155 ValLoss:  1.6337288618087769 \n","\n","Epoch  266 TrAcc:  0.8944262346206527 ValAcc:  0.19466423641934094 TrLoss:  0.08322187513113022 ValLoss:  1.6218934059143066 \n","\n","Epoch  267 TrAcc:  0.8762276093304606 ValAcc:  0.20137270895627082 TrLoss:  0.09325546026229858 ValLoss:  1.723848819732666 \n","\n","Epoch  268 TrAcc:  0.8190627794297584 ValAcc:  0.21155013144527401 TrLoss:  0.13205967843532562 ValLoss:  1.804909110069275 \n","\n","Epoch  269 TrAcc:  0.8236149683071592 ValAcc:  0.19213543506781464 TrLoss:  0.12580451369285583 ValLoss:  1.7786792516708374 \n","\n","Epoch  270 TrAcc:  0.7911716505454343 ValAcc:  0.19516611507895146 TrLoss:  0.10719160735607147 ValLoss:  1.6257383823394775 \n","\n","Epoch  271 TrAcc:  0.8202816301279952 ValAcc:  0.20450306473722957 TrLoss:  0.10776232928037643 ValLoss:  1.7402958869934082 \n","\n","Epoch  272 TrAcc:  0.8507008410121198 ValAcc:  0.20384958134796183 TrLoss:  0.08885754644870758 ValLoss:  1.6323065757751465 \n","\n","Epoch  273 TrAcc:  0.8772598787200115 ValAcc:  0.20281765866904655 TrLoss:  0.08100124448537827 ValLoss:  1.6713590621948242 \n","\n","Epoch  274 TrAcc:  0.8980070691134237 ValAcc:  0.19247488590757478 TrLoss:  0.08041229844093323 ValLoss:  1.698981523513794 \n","\n","Epoch  275 TrAcc:  0.8987737707363429 ValAcc:  0.2008685823000187 TrLoss:  0.07510249316692352 ValLoss:  1.647836685180664 \n","\n","Epoch  276 TrAcc:  0.9158968670725274 ValAcc:  0.20121299390120262 TrLoss:  0.07823330163955688 ValLoss:  1.8614065647125244 \n","\n","Epoch  277 TrAcc:  0.9225950750730383 ValAcc:  0.19877126311557677 TrLoss:  0.06408553570508957 ValLoss:  1.7398998737335205 \n","\n","Epoch  278 TrAcc:  0.9299017501231766 ValAcc:  0.20377566319596707 TrLoss:  0.06263328343629837 ValLoss:  1.6521875858306885 \n","\n","Epoch  279 TrAcc:  0.932153488852598 ValAcc:  0.20435734638956382 TrLoss:  0.06302838027477264 ValLoss:  1.8529386520385742 \n","\n","Epoch  280 TrAcc:  0.9246728821859722 ValAcc:  0.20372364921980454 TrLoss:  0.06579716503620148 ValLoss:  1.7102590799331665 \n","\n","Epoch  281 TrAcc:  0.9234948295362496 ValAcc:  0.2020748129426484 TrLoss:  0.07456319034099579 ValLoss:  1.8950176239013672 \n","\n","Epoch  282 TrAcc:  0.9208175343524361 ValAcc:  0.19528010472428048 TrLoss:  0.07632605731487274 ValLoss:  1.8060673475265503 \n","\n","Epoch  283 TrAcc:  0.9307336811075682 ValAcc:  0.19064648017219865 TrLoss:  0.06157226115465164 ValLoss:  1.9225554466247559 \n","\n","Epoch  284 TrAcc:  0.9399634434980021 ValAcc:  0.2004478180416648 TrLoss:  0.04935406893491745 ValLoss:  1.9527488946914673 \n","\n","Epoch  285 TrAcc:  0.9530992213468875 ValAcc:  0.19635314571705106 TrLoss:  0.05213396996259689 ValLoss:  1.9112005233764648 \n","\n","Epoch  286 TrAcc:  0.9503694022076447 ValAcc:  0.19446259294523913 TrLoss:  0.07477404922246933 ValLoss:  1.7031564712524414 \n","\n","Epoch  287 TrAcc:  0.9380997219386457 ValAcc:  0.20117960596989673 TrLoss:  0.06804563105106354 ValLoss:  1.71736478805542 \n","\n","Epoch  288 TrAcc:  0.9332309500187084 ValAcc:  0.19880658841620014 TrLoss:  0.06520858407020569 ValLoss:  1.836303949356079 \n","\n","Epoch  289 TrAcc:  0.9391883472637288 ValAcc:  0.1965190395384568 TrLoss:  0.04608193412423134 ValLoss:  1.773802399635315 \n","\n","Epoch  290 TrAcc:  0.9521667529776 ValAcc:  0.21157759992318292 TrLoss:  0.04498396813869476 ValLoss:  1.618046522140503 \n","\n","Epoch  291 TrAcc:  0.9576875264489155 ValAcc:  0.1925542985064267 TrLoss:  0.050390031188726425 ValLoss:  1.9747421741485596 \n","\n","Epoch  292 TrAcc:  0.960189689418132 ValAcc:  0.20078050214643303 TrLoss:  0.04421321675181389 ValLoss:  1.8852088451385498 \n","\n","Epoch  293 TrAcc:  0.9644486101527536 ValAcc:  0.20050734090606337 TrLoss:  0.03898454084992409 ValLoss:  1.9238296747207642 \n","\n","Epoch  294 TrAcc:  0.9569324039785176 ValAcc:  0.20906033908016744 TrLoss:  0.05831873044371605 ValLoss:  1.853908896446228 \n","\n","Epoch  295 TrAcc:  0.9327382126122291 ValAcc:  0.1918891204656922 TrLoss:  0.07496039569377899 ValLoss:  1.8014235496520996 \n","\n","Epoch  296 TrAcc:  0.9232798904063192 ValAcc:  0.1941859967642374 TrLoss:  0.06253831088542938 ValLoss:  1.8689707517623901 \n","\n","Epoch  297 TrAcc:  0.9305192440741317 ValAcc:  0.1924035434581415 TrLoss:  0.05842895433306694 ValLoss:  1.9009501934051514 \n","\n","Epoch  298 TrAcc:  0.9298074279469577 ValAcc:  0.19901429740853896 TrLoss:  0.0707448348402977 ValLoss:  1.9199612140655518 \n","\n","Epoch  299 TrAcc:  0.9327003874671174 ValAcc:  0.20861650500271636 TrLoss:  0.05233915150165558 ValLoss:  2.021951913833618 \n","\n","Epoch  300 TrAcc:  0.9255949998341186 ValAcc:  0.1989120951505641 TrLoss:  0.08550132811069489 ValLoss:  1.9828490018844604 \n","\n","Epoch  301 TrAcc:  0.7135877687958347 ValAcc:  0.18472547878885692 TrLoss:  0.17356029152870178 ValLoss:  1.9210541248321533 \n","\n","Epoch  302 TrAcc:  0.6782720520595883 ValAcc:  0.19668257294195876 TrLoss:  0.22402827441692352 ValLoss:  1.9098541736602783 \n","\n","Epoch  303 TrAcc:  0.6849657744705061 ValAcc:  0.1864456527497429 TrLoss:  0.1567687690258026 ValLoss:  1.7937450408935547 \n","\n","Epoch  304 TrAcc:  0.7139518537450681 ValAcc:  0.19236809324846393 TrLoss:  0.1375325322151184 ValLoss:  1.8271313905715942 \n","\n","Epoch  305 TrAcc:  0.7974767731570482 ValAcc:  0.20354734374272462 TrLoss:  0.12226662039756775 ValLoss:  1.9771900177001953 \n","\n","Epoch  306 TrAcc:  0.8332102388754358 ValAcc:  0.19910069076538217 TrLoss:  0.0898897647857666 ValLoss:  1.71221125125885 \n","\n","Epoch  307 TrAcc:  0.880628510430881 ValAcc:  0.20507671673970962 TrLoss:  0.07189559936523438 ValLoss:  1.9990551471710205 \n","\n","Epoch  308 TrAcc:  0.9260552184219284 ValAcc:  0.20400097335460432 TrLoss:  0.06360259652137756 ValLoss:  1.8564541339874268 \n","\n","Epoch  309 TrAcc:  0.945241144733595 ValAcc:  0.19495294837960087 TrLoss:  0.04066181927919388 ValLoss:  2.0743768215179443 \n","\n","Epoch  310 TrAcc:  0.9613802181535113 ValAcc:  0.2056987994675763 TrLoss:  0.04642900824546814 ValLoss:  1.8889617919921875 \n","\n","Epoch  311 TrAcc:  0.9676809459130046 ValAcc:  0.2064062333163417 TrLoss:  0.040812186896800995 ValLoss:  1.8682498931884766 \n","\n","Epoch  312 TrAcc:  0.9787362132203468 ValAcc:  0.2037888054457885 TrLoss:  0.03201708570122719 ValLoss:  1.9120198488235474 \n","\n","Epoch  313 TrAcc:  0.9800796388926103 ValAcc:  0.20510032066174488 TrLoss:  0.027825888246297836 ValLoss:  1.825455904006958 \n","\n","Epoch  314 TrAcc:  0.9835226104178686 ValAcc:  0.2051514313849789 TrLoss:  0.02133599855005741 ValLoss:  1.9013181924819946 \n","\n","Epoch  315 TrAcc:  0.9867241641808282 ValAcc:  0.2028100870720062 TrLoss:  0.024614989757537842 ValLoss:  1.761291265487671 \n","\n","Epoch  316 TrAcc:  0.9888330956713205 ValAcc:  0.19974097166486682 TrLoss:  0.022065242752432823 ValLoss:  1.901975393295288 \n","\n","Epoch  317 TrAcc:  0.9902110865283573 ValAcc:  0.20462785940545192 TrLoss:  0.019524283707141876 ValLoss:  2.026528835296631 \n","\n","Epoch  318 TrAcc:  0.9902306415920776 ValAcc:  0.19716870279059526 TrLoss:  0.019799508154392242 ValLoss:  1.9813470840454102 \n","\n","Epoch  319 TrAcc:  0.9925185647736902 ValAcc:  0.20627084818615693 TrLoss:  0.017555400729179382 ValLoss:  1.8057045936584473 \n","\n","Epoch  320 TrAcc:  0.992371307102363 ValAcc:  0.19438176086774495 TrLoss:  0.016112452372908592 ValLoss:  1.8524858951568604 \n","\n","Epoch  321 TrAcc:  0.9933735081483749 ValAcc:  0.20467355211090169 TrLoss:  0.01791701465845108 ValLoss:  1.906998634338379 \n","\n","Epoch  322 TrAcc:  0.9939428965649096 ValAcc:  0.20116527568212905 TrLoss:  0.014123018831014633 ValLoss:  2.1696505546569824 \n","\n","Epoch  323 TrAcc:  0.9929544564919109 ValAcc:  0.20263102134042343 TrLoss:  0.01734134741127491 ValLoss:  2.1558146476745605 \n","\n","Epoch  324 TrAcc:  0.9947224308528224 ValAcc:  0.20446606221446062 TrLoss:  0.014965142123401165 ValLoss:  2.003970146179199 \n","\n","Epoch  325 TrAcc:  0.9947130750911823 ValAcc:  0.20299780862985972 TrLoss:  0.013074370101094246 ValLoss:  1.9030821323394775 \n","\n","Epoch  326 TrAcc:  0.9953057747722973 ValAcc:  0.19716338806363443 TrLoss:  0.015300176106393337 ValLoss:  2.2300217151641846 \n","\n","Epoch  327 TrAcc:  0.9952820236160197 ValAcc:  0.20336579392794377 TrLoss:  0.015186802484095097 ValLoss:  1.977938175201416 \n","\n","Epoch  328 TrAcc:  0.9938405178070401 ValAcc:  0.20486737029052185 TrLoss:  0.019654184579849243 ValLoss:  2.0245537757873535 \n","\n","Epoch  329 TrAcc:  0.9894606784258094 ValAcc:  0.20544681406656007 TrLoss:  0.04725175350904465 ValLoss:  2.1704413890838623 \n","\n","Epoch  330 TrAcc:  0.9630995569649344 ValAcc:  0.20064024686641704 TrLoss:  0.04655399173498154 ValLoss:  2.143509864807129 \n","\n","Epoch  331 TrAcc:  0.9367578030725121 ValAcc:  0.20615393894148393 TrLoss:  0.05481763184070587 ValLoss:  1.9008355140686035 \n","\n","Epoch  332 TrAcc:  0.9121931180937456 ValAcc:  0.20540595744985843 TrLoss:  0.0611443854868412 ValLoss:  1.980726957321167 \n","\n","Epoch  333 TrAcc:  0.8659203359367605 ValAcc:  0.2004148894229206 TrLoss:  0.0860641747713089 ValLoss:  1.9129886627197266 \n","\n","Epoch  334 TrAcc:  0.8545337243196772 ValAcc:  0.1958637857168426 TrLoss:  0.11644147336483002 ValLoss:  2.0698604583740234 \n","\n","Epoch  335 TrAcc:  0.8384796927173593 ValAcc:  0.19842719619813087 TrLoss:  0.10871680825948715 ValLoss:  2.0210189819335938 \n","\n","Epoch  336 TrAcc:  0.8250825241552991 ValAcc:  0.2004402162677376 TrLoss:  0.1249384805560112 ValLoss:  1.9071730375289917 \n","\n","Epoch  337 TrAcc:  0.7991262838895443 ValAcc:  0.19660112633969837 TrLoss:  0.11167573928833008 ValLoss:  1.9793918132781982 \n","\n","Epoch  338 TrAcc:  0.8372002023931171 ValAcc:  0.2021716263418388 TrLoss:  0.07524267584085464 ValLoss:  1.9883146286010742 \n","\n","Epoch  339 TrAcc:  0.8776406978700799 ValAcc:  0.19972592464457126 TrLoss:  0.06736267358064651 ValLoss:  1.9352054595947266 \n","\n","Epoch  340 TrAcc:  0.9166919405797351 ValAcc:  0.19438700932738243 TrLoss:  0.06706325709819794 ValLoss:  2.070390224456787 \n","\n","Epoch  341 TrAcc:  0.9332099755291793 ValAcc:  0.19945113424569993 TrLoss:  0.04636923596262932 ValLoss:  2.141664743423462 \n","\n","Epoch  342 TrAcc:  0.9551139331385551 ValAcc:  0.19171280476713573 TrLoss:  0.044684410095214844 ValLoss:  2.038184642791748 \n","\n","Epoch  343 TrAcc:  0.9653999692047321 ValAcc:  0.20597190945503938 TrLoss:  0.025840360671281815 ValLoss:  1.949056625366211 \n","\n","Epoch  344 TrAcc:  0.9770143626353689 ValAcc:  0.19774963795514075 TrLoss:  0.02196880802512169 ValLoss:  2.1810765266418457 \n","\n","Epoch  345 TrAcc:  0.9277075411342176 ValAcc:  0.2111077958486605 TrLoss:  0.1158888190984726 ValLoss:  2.2312591075897217 \n","\n","Epoch  346 TrAcc:  0.8547997155935899 ValAcc:  0.19354235375576465 TrLoss:  0.15558601915836334 ValLoss:  2.1890878677368164 \n","\n","Epoch  347 TrAcc:  0.83920845028261 ValAcc:  0.19073063759373854 TrLoss:  0.10313989222049713 ValLoss:  1.980373740196228 \n","\n","Epoch  348 TrAcc:  0.8789716614054355 ValAcc:  0.1964669321672704 TrLoss:  0.06664309650659561 ValLoss:  1.953381061553955 \n","\n","Epoch  349 TrAcc:  0.9238741152013202 ValAcc:  0.20514789555641388 TrLoss:  0.04161408543586731 ValLoss:  1.9741201400756836 \n","\n","Epoch  350 TrAcc:  0.962471958304246 ValAcc:  0.19487967994106833 TrLoss:  0.033328134566545486 ValLoss:  2.0530831813812256 \n","\n","Epoch  351 TrAcc:  0.9733929280486916 ValAcc:  0.20048706861049115 TrLoss:  0.03323042765259743 ValLoss:  1.936132788658142 \n","\n","Epoch  352 TrAcc:  0.9814636014615168 ValAcc:  0.19144847663249479 TrLoss:  0.027307165786623955 ValLoss:  1.9561736583709717 \n","\n","Epoch  353 TrAcc:  0.9873893090764703 ValAcc:  0.2019854532309734 TrLoss:  0.019601736217737198 ValLoss:  2.1166727542877197 \n","\n","Epoch  354 TrAcc:  0.990143443202577 ValAcc:  0.19991787031268085 TrLoss:  0.015689384192228317 ValLoss:  1.9335544109344482 \n","\n","Epoch  355 TrAcc:  0.9904940398020174 ValAcc:  0.19481573795447746 TrLoss:  0.01893843337893486 ValLoss:  1.9271297454833984 \n","\n","Epoch  356 TrAcc:  0.9842246633565813 ValAcc:  0.1994021595579574 TrLoss:  0.026638925075531006 ValLoss:  1.8688414096832275 \n","\n","Epoch  357 TrAcc:  0.9850404292889716 ValAcc:  0.20433365335805842 TrLoss:  0.025051411241292953 ValLoss:  2.19793701171875 \n","\n","Epoch  358 TrAcc:  0.9862395877535937 ValAcc:  0.19848412577554178 TrLoss:  0.04867691546678543 ValLoss:  1.9518887996673584 \n","\n","Epoch  359 TrAcc:  0.9887246269953224 ValAcc:  0.19702200770855913 TrLoss:  0.025682955980300903 ValLoss:  2.0893120765686035 \n","\n","Epoch  360 TrAcc:  0.9860451174105783 ValAcc:  0.19403191718843435 TrLoss:  0.037852849811315536 ValLoss:  2.1364903450012207 \n","\n","Epoch  361 TrAcc:  0.9885437295119579 ValAcc:  0.20401149358683804 TrLoss:  0.028231479227542877 ValLoss:  1.9650986194610596 \n","\n","Epoch  362 TrAcc:  0.9895255628095461 ValAcc:  0.20073405365599073 TrLoss:  0.018255718052387238 ValLoss:  2.1419663429260254 \n","\n","Epoch  363 TrAcc:  0.9903008461151412 ValAcc:  0.19703190022688047 TrLoss:  0.02335328981280327 ValLoss:  2.1427161693573 \n","\n","Epoch  364 TrAcc:  0.9943753563992439 ValAcc:  0.19231750543705275 TrLoss:  0.01198318600654602 ValLoss:  1.9878778457641602 \n","\n","Epoch  365 TrAcc:  0.9940409659875711 ValAcc:  0.19751351275699477 TrLoss:  0.014055272564291954 ValLoss:  2.2947916984558105 \n","\n","Epoch  366 TrAcc:  0.9965299505259944 ValAcc:  0.1944276391574196 TrLoss:  0.011346802115440369 ValLoss:  2.338322162628174 \n","\n","Epoch  367 TrAcc:  0.9972297224656559 ValAcc:  0.198699355790217 TrLoss:  0.00854786392301321 ValLoss:  2.148334503173828 \n","\n","Epoch  368 TrAcc:  0.99612807577321 ValAcc:  0.20603567740785492 TrLoss:  0.007296447642147541 ValLoss:  2.128833770751953 \n","\n","Epoch  369 TrAcc:  0.9977718090313735 ValAcc:  0.20054530604819168 TrLoss:  0.009112164378166199 ValLoss:  2.1149120330810547 \n","\n","Epoch  370 TrAcc:  0.9966243783370677 ValAcc:  0.2004215076987426 TrLoss:  0.008539669215679169 ValLoss:  2.1442508697509766 \n","\n","Epoch  371 TrAcc:  0.9966962892934361 ValAcc:  0.19709898880511934 TrLoss:  0.008891560137271881 ValLoss:  2.2338039875030518 \n","\n","Epoch  372 TrAcc:  0.9964845222512464 ValAcc:  0.1954649889588769 TrLoss:  0.009311274625360966 ValLoss:  2.1033759117126465 \n","\n","Epoch  373 TrAcc:  0.9974643271111198 ValAcc:  0.1929036710628067 TrLoss:  0.008823506534099579 ValLoss:  2.0441737174987793 \n","\n","Epoch  374 TrAcc:  0.9977742359522789 ValAcc:  0.20722102890982338 TrLoss:  0.010382037609815598 ValLoss:  2.2116000652313232 \n","\n","Epoch  375 TrAcc:  0.9970971094877348 ValAcc:  0.19659752227496144 TrLoss:  0.0095865149050951 ValLoss:  2.2946205139160156 \n","\n","Epoch  376 TrAcc:  0.9971350473287014 ValAcc:  0.1997627882224564 TrLoss:  0.01686478778719902 ValLoss:  2.00750470161438 \n","\n","Epoch  377 TrAcc:  0.9968523231020571 ValAcc:  0.18916413826686285 TrLoss:  0.010959528386592865 ValLoss:  2.1982290744781494 \n","\n","Epoch  378 TrAcc:  0.986620762574918 ValAcc:  0.19432647828170235 TrLoss:  0.033274196088314056 ValLoss:  2.1506550312042236 \n","\n","Epoch  379 TrAcc:  0.8647236786474618 ValAcc:  0.19277433942862496 TrLoss:  0.15685635805130005 ValLoss:  2.115643262863159 \n","\n","Epoch  380 TrAcc:  0.7637599103296132 ValAcc:  0.1862077313652696 TrLoss:  0.1634705662727356 ValLoss:  1.9879558086395264 \n","\n","Epoch  381 TrAcc:  0.7079935327081439 ValAcc:  0.18939348684297216 TrLoss:  0.20103347301483154 ValLoss:  2.168036699295044 \n","\n","Epoch  382 TrAcc:  0.6927991106630857 ValAcc:  0.18954541975967198 TrLoss:  0.18838658928871155 ValLoss:  2.2835264205932617 \n","\n","Epoch  383 TrAcc:  0.6982044112832085 ValAcc:  0.19764823783628893 TrLoss:  0.24538937211036682 ValLoss:  2.1224067211151123 \n","\n","Epoch  384 TrAcc:  0.6496769231116309 ValAcc:  0.20073823940813215 TrLoss:  0.24368524551391602 ValLoss:  1.933846354484558 \n","\n","Epoch  385 TrAcc:  0.7295187938470943 ValAcc:  0.19679583042847995 TrLoss:  0.15219596028327942 ValLoss:  1.8516192436218262 \n","\n","Epoch  386 TrAcc:  0.8235715611475815 ValAcc:  0.20179738250441426 TrLoss:  0.09877602010965347 ValLoss:  1.9643741846084595 \n","\n","Epoch  387 TrAcc:  0.8990512089424111 ValAcc:  0.1891192745091738 TrLoss:  0.05255734920501709 ValLoss:  2.06534481048584 \n","\n","Epoch  388 TrAcc:  0.9474417323923818 ValAcc:  0.2019011373404576 TrLoss:  0.038831643760204315 ValLoss:  1.9066506624221802 \n","\n","Epoch  389 TrAcc:  0.9730741608009478 ValAcc:  0.20504996311828072 TrLoss:  0.020715685561299324 ValLoss:  1.9400851726531982 \n","\n","Epoch  390 TrAcc:  0.9846098781739866 ValAcc:  0.19526490927205195 TrLoss:  0.024888142943382263 ValLoss:  2.079031229019165 \n","\n","Epoch  391 TrAcc:  0.9905209265978528 ValAcc:  0.1978373013345808 TrLoss:  0.017641860991716385 ValLoss:  2.123020648956299 \n","\n","Epoch  392 TrAcc:  0.9926847202345566 ValAcc:  0.19644898631139732 TrLoss:  0.018701430410146713 ValLoss:  2.0316848754882812 \n","\n","Epoch  393 TrAcc:  0.9939729072045351 ValAcc:  0.19619767740466076 TrLoss:  0.011396601796150208 ValLoss:  2.042264461517334 \n","\n","Epoch  394 TrAcc:  0.9961078689821296 ValAcc:  0.1929969339765989 TrLoss:  0.010883685201406479 ValLoss:  2.3955321311950684 \n","\n","Epoch  395 TrAcc:  0.9967526781516828 ValAcc:  0.19744978307377356 TrLoss:  0.009165562689304352 ValLoss:  2.1072583198547363 \n","\n","Epoch  396 TrAcc:  0.997119604210051 ValAcc:  0.19594333170538977 TrLoss:  0.010601108893752098 ValLoss:  2.196638584136963 \n","\n","Epoch  397 TrAcc:  0.998213879253278 ValAcc:  0.1970719175391322 TrLoss:  0.010054763406515121 ValLoss:  2.2605199813842773 \n","\n","Epoch  398 TrAcc:  0.9976668725426683 ValAcc:  0.19340679535016145 TrLoss:  0.008829928934574127 ValLoss:  2.22926664352417 \n","\n","Epoch  399 TrAcc:  0.9982287766333975 ValAcc:  0.19525555834685385 TrLoss:  0.008359602652490139 ValLoss:  2.382859945297241 \n","\n","Epoch  400 TrAcc:  0.9985333936849249 ValAcc:  0.19340244819036226 TrLoss:  0.007258563302457333 ValLoss:  2.1799657344818115 \n","\n","Epoch  401 TrAcc:  0.9984325825271284 ValAcc:  0.19627751433768711 TrLoss:  0.007642955984920263 ValLoss:  2.245267868041992 \n","\n","Epoch  402 TrAcc:  0.998677759123408 ValAcc:  0.1999166433327744 TrLoss:  0.008568908087909222 ValLoss:  2.3349504470825195 \n","\n","Epoch  403 TrAcc:  0.9985636632056668 ValAcc:  0.2031688420571093 TrLoss:  0.007159061264246702 ValLoss:  2.386551856994629 \n","\n","Epoch  404 TrAcc:  0.9982785094807154 ValAcc:  0.19805756217951567 TrLoss:  0.007322569843381643 ValLoss:  2.2452287673950195 \n","\n","Epoch  405 TrAcc:  0.9985087987814968 ValAcc:  0.19853588660912058 TrLoss:  0.007939981296658516 ValLoss:  2.269226551055908 \n","\n","Epoch  406 TrAcc:  0.9983373683608059 ValAcc:  0.19444950880116288 TrLoss:  0.006432069465517998 ValLoss:  2.5727591514587402 \n","\n","Epoch  407 TrAcc:  0.9992464630779848 ValAcc:  0.19011669980625054 TrLoss:  0.0048356689512729645 ValLoss:  2.0734591484069824 \n","\n","Epoch  408 TrAcc:  0.9991565573240168 ValAcc:  0.18951437199864504 TrLoss:  0.006240000016987324 ValLoss:  2.3884153366088867 \n","\n","Epoch  409 TrAcc:  0.9993450493875087 ValAcc:  0.19612556901957504 TrLoss:  0.0054692113772034645 ValLoss:  2.2506015300750732 \n","\n","Epoch  410 TrAcc:  0.9994388640873015 ValAcc:  0.195703697012225 TrLoss:  0.005929135717451572 ValLoss:  2.2757182121276855 \n","\n","Epoch  411 TrAcc:  0.9992126736111112 ValAcc:  0.19168911731552643 TrLoss:  0.006459287367761135 ValLoss:  2.1602401733398438 \n","\n","Epoch  412 TrAcc:  0.9991404819139192 ValAcc:  0.19559363316155218 TrLoss:  0.0056846123188734055 ValLoss:  2.400847911834717 \n","\n","Epoch  413 TrAcc:  0.9992424355158731 ValAcc:  0.1947814597667845 TrLoss:  0.00591577123850584 ValLoss:  2.3277409076690674 \n","\n","Epoch  414 TrAcc:  0.9990966021825397 ValAcc:  0.1941383927955871 TrLoss:  0.0074502271600067616 ValLoss:  2.201450824737549 \n","\n","Epoch  415 TrAcc:  0.9986980215964588 ValAcc:  0.19649241145350674 TrLoss:  0.007029694505035877 ValLoss:  2.339231491088867 \n","\n","Epoch  416 TrAcc:  0.998731626625009 ValAcc:  0.1988212250568285 TrLoss:  0.006557483226060867 ValLoss:  2.3788604736328125 \n","\n","Epoch  417 TrAcc:  0.9969610552158307 ValAcc:  0.19718177332296202 TrLoss:  0.011345506645739079 ValLoss:  2.149136781692505 \n","\n","Epoch  418 TrAcc:  0.9942666988342542 ValAcc:  0.1955110097348338 TrLoss:  0.021762702614068985 ValLoss:  2.197479724884033 \n","\n","Epoch  419 TrAcc:  0.988502867896637 ValAcc:  0.19982411561043986 TrLoss:  0.036634381860494614 ValLoss:  2.13897705078125 \n","\n","Epoch  420 TrAcc:  0.9716097724118962 ValAcc:  0.19521779009640663 TrLoss:  0.04458646476268768 ValLoss:  2.237797975540161 \n","\n","Epoch  421 TrAcc:  0.9539709304371936 ValAcc:  0.18667978260784432 TrLoss:  0.04598735272884369 ValLoss:  2.335285186767578 \n","\n","Epoch  422 TrAcc:  0.93509110150711 ValAcc:  0.19283444753077594 TrLoss:  0.05804549902677536 ValLoss:  2.0871565341949463 \n","\n","Epoch  423 TrAcc:  0.9231390875757164 ValAcc:  0.2100277439289883 TrLoss:  0.059736885130405426 ValLoss:  2.14508056640625 \n","\n","Epoch  424 TrAcc:  0.9070358120311858 ValAcc:  0.1870309323846244 TrLoss:  0.06508812308311462 ValLoss:  2.102867603302002 \n","\n","Epoch  425 TrAcc:  0.9078062934195011 ValAcc:  0.18861406448729992 TrLoss:  0.06800247728824615 ValLoss:  2.153052806854248 \n","\n","Epoch  426 TrAcc:  0.9145410757326937 ValAcc:  0.18838170469228874 TrLoss:  0.050616323947906494 ValLoss:  2.1998753547668457 \n","\n","Epoch  427 TrAcc:  0.923894715224395 ValAcc:  0.19463015633382086 TrLoss:  0.04208282381296158 ValLoss:  2.185480833053589 \n","\n","Epoch  428 TrAcc:  0.9186956631283394 ValAcc:  0.19081585939726856 TrLoss:  0.06648667901754379 ValLoss:  2.3135972023010254 \n","\n","Epoch  429 TrAcc:  0.9328103119378572 ValAcc:  0.19011157041721385 TrLoss:  0.046487804502248764 ValLoss:  2.1206202507019043 \n","\n","Epoch  430 TrAcc:  0.9479874199433235 ValAcc:  0.19626552781665474 TrLoss:  0.03772604092955589 ValLoss:  2.3060221672058105 \n","\n","Epoch  431 TrAcc:  0.9579600692781396 ValAcc:  0.19685826250732355 TrLoss:  0.03158637136220932 ValLoss:  2.081805467605591 \n","\n","Epoch  432 TrAcc:  0.9724513253963858 ValAcc:  0.17827288868781666 TrLoss:  0.03508829325437546 ValLoss:  2.5200610160827637 \n","\n","Epoch  433 TrAcc:  0.981373309184344 ValAcc:  0.1901187915615171 TrLoss:  0.01783021353185177 ValLoss:  2.2236461639404297 \n","\n","Epoch  434 TrAcc:  0.9875010125792117 ValAcc:  0.19425693911773587 TrLoss:  0.01948520913720131 ValLoss:  2.1389458179473877 \n","\n","Epoch  435 TrAcc:  0.9888928176072358 ValAcc:  0.19179714857503127 TrLoss:  0.01734967716038227 ValLoss:  2.197359085083008 \n","\n","Epoch  436 TrAcc:  0.988759745508345 ValAcc:  0.19788608076428074 TrLoss:  0.01796318218111992 ValLoss:  2.0829806327819824 \n","\n","Epoch  437 TrAcc:  0.9917816121615006 ValAcc:  0.18447970944713019 TrLoss:  0.015984641388058662 ValLoss:  2.3871688842773438 \n","\n","Epoch  438 TrAcc:  0.9948296114759075 ValAcc:  0.19363590342361783 TrLoss:  0.012419406324625015 ValLoss:  2.5510950088500977 \n","\n","Epoch  439 TrAcc:  0.9972246231227574 ValAcc:  0.19377210148482363 TrLoss:  0.009941067546606064 ValLoss:  2.263977289199829 \n","\n","Epoch  440 TrAcc:  0.9960660039222321 ValAcc:  0.19216104861046776 TrLoss:  0.00936649739742279 ValLoss:  2.079392194747925 \n","\n","Epoch  441 TrAcc:  0.9926281705181296 ValAcc:  0.1981108034073714 TrLoss:  0.02658548206090927 ValLoss:  2.3912477493286133 \n","\n","Epoch  442 TrAcc:  0.9833576059900767 ValAcc:  0.19034105244469088 TrLoss:  0.021832264959812164 ValLoss:  2.2591397762298584 \n","\n","Epoch  443 TrAcc:  0.8029022360376168 ValAcc:  0.1920124038814359 TrLoss:  0.2973073124885559 ValLoss:  2.2688589096069336 \n","\n","Epoch  444 TrAcc:  0.6585256260562162 ValAcc:  0.17514170413244143 TrLoss:  0.2342652678489685 ValLoss:  2.0338876247406006 \n","\n","Epoch  445 TrAcc:  0.699125180485832 ValAcc:  0.1909424486018377 TrLoss:  0.168227881193161 ValLoss:  1.8728766441345215 \n","\n","Epoch  446 TrAcc:  0.7881021808369784 ValAcc:  0.2044350679401662 TrLoss:  0.11133541166782379 ValLoss:  2.0183393955230713 \n","\n","Epoch  447 TrAcc:  0.8745618917287813 ValAcc:  0.19717811622440548 TrLoss:  0.0733235627412796 ValLoss:  2.07448673248291 \n","\n","Epoch  448 TrAcc:  0.9402841673765883 ValAcc:  0.20284802208277253 TrLoss:  0.037121497094631195 ValLoss:  2.112786293029785 \n","\n","Epoch  449 TrAcc:  0.9691765186676817 ValAcc:  0.19170931297599703 TrLoss:  0.029651129618287086 ValLoss:  2.1435208320617676 \n","\n","Epoch  450 TrAcc:  0.985323001869845 ValAcc:  0.20060220182716273 TrLoss:  0.017083708196878433 ValLoss:  2.312826633453369 \n","\n","Epoch  451 TrAcc:  0.9933128342716304 ValAcc:  0.2043702030724699 TrLoss:  0.013324754312634468 ValLoss:  2.1768667697906494 \n","\n","Epoch  452 TrAcc:  0.9951412156703243 ValAcc:  0.2074066313331566 TrLoss:  0.01141400821506977 ValLoss:  2.018685817718506 \n","\n","Epoch  453 TrAcc:  0.9968671035487858 ValAcc:  0.20041307661888738 TrLoss:  0.009676674380898476 ValLoss:  2.1988425254821777 \n","\n","Epoch  454 TrAcc:  0.998644427531992 ValAcc:  0.20144129358113416 TrLoss:  0.007729846052825451 ValLoss:  2.1762542724609375 \n","\n","Epoch  455 TrAcc:  0.9985602751517274 ValAcc:  0.19616368818481647 TrLoss:  0.006619633175432682 ValLoss:  2.3460545539855957 \n","\n","Epoch  456 TrAcc:  0.9989764530812324 ValAcc:  0.1977629013584181 TrLoss:  0.007012970745563507 ValLoss:  2.2801804542541504 \n","\n","Epoch  457 TrAcc:  0.9988482863643707 ValAcc:  0.19699959701954636 TrLoss:  0.005844434257596731 ValLoss:  2.470183849334717 \n","\n","Epoch  458 TrAcc:  0.9993653346755369 ValAcc:  0.20207475042275222 TrLoss:  0.006194844376295805 ValLoss:  2.2752301692962646 \n","\n","Epoch  459 TrAcc:  0.999322352994228 ValAcc:  0.2056242715094376 TrLoss:  0.005624883342534304 ValLoss:  2.233971118927002 \n","\n","Epoch  460 TrAcc:  0.9995341678338002 ValAcc:  0.20037602220800557 TrLoss:  0.00565582187846303 ValLoss:  2.3640453815460205 \n","\n","Epoch  461 TrAcc:  0.9994168974407945 ValAcc:  0.2060357740962255 TrLoss:  0.006368777249008417 ValLoss:  2.0417637825012207 \n","\n","Epoch  462 TrAcc:  0.9995709325396827 ValAcc:  0.2061476096745607 TrLoss:  0.004758462309837341 ValLoss:  2.2376821041107178 \n","\n","Epoch  463 TrAcc:  0.9993249060988033 ValAcc:  0.20258459473104987 TrLoss:  0.004120740108191967 ValLoss:  2.2853004932403564 \n","\n","Epoch  464 TrAcc:  0.9992680879169851 ValAcc:  0.20239503670601403 TrLoss:  0.005731288343667984 ValLoss:  2.3070859909057617 \n","\n","Epoch  465 TrAcc:  0.9996056547619048 ValAcc:  0.20211978867958072 TrLoss:  0.003919356968253851 ValLoss:  2.4702510833740234 \n","\n","Epoch  466 TrAcc:  0.9996056547619048 ValAcc:  0.19536659837859635 TrLoss:  0.0036877586971968412 ValLoss:  2.18025803565979 \n","\n","Epoch  467 TrAcc:  0.9992993750530514 ValAcc:  0.19846908480264666 TrLoss:  0.004125072155147791 ValLoss:  2.3561246395111084 \n","\n","Epoch  468 TrAcc:  0.9994606384220356 ValAcc:  0.20508781718154398 TrLoss:  0.0034145985264331102 ValLoss:  2.2953555583953857 \n","\n","Epoch  469 TrAcc:  0.9993048526228674 ValAcc:  0.19873883919641566 TrLoss:  0.003779113758355379 ValLoss:  2.230353832244873 \n","\n","Epoch  470 TrAcc:  0.9997619047619049 ValAcc:  0.20071848105366988 TrLoss:  0.0044633480720222 ValLoss:  2.38936448097229 \n","\n","Epoch  471 TrAcc:  0.9995709325396825 ValAcc:  0.19927968889736114 TrLoss:  0.004538209177553654 ValLoss:  2.211792230606079 \n","\n","Epoch  472 TrAcc:  0.9990740307486634 ValAcc:  0.20678384313333184 TrLoss:  0.013052655383944511 ValLoss:  2.477450370788574 \n","\n","Epoch  473 TrAcc:  0.9826779117087118 ValAcc:  0.19258301977055667 TrLoss:  0.0321260541677475 ValLoss:  2.235811233520508 \n","\n","Epoch  474 TrAcc:  0.9734289022128755 ValAcc:  0.18013854010305833 TrLoss:  0.024051226675510406 ValLoss:  2.4095726013183594 \n","\n","Epoch  475 TrAcc:  0.9549686608126126 ValAcc:  0.18542589763975656 TrLoss:  0.050877075642347336 ValLoss:  2.3781650066375732 \n","\n","Epoch  476 TrAcc:  0.8796011724330693 ValAcc:  0.19949386358227558 TrLoss:  0.0613567978143692 ValLoss:  2.2776436805725098 \n","\n","Epoch  477 TrAcc:  0.784838949371167 ValAcc:  0.19484609707603537 TrLoss:  0.1616297960281372 ValLoss:  2.227867603302002 \n","\n","Epoch  478 TrAcc:  0.7722678916157849 ValAcc:  0.1890862420147885 TrLoss:  0.10783682763576508 ValLoss:  2.1938629150390625 \n","\n","Epoch  479 TrAcc:  0.8108332652354746 ValAcc:  0.19750357183184297 TrLoss:  0.08882565051317215 ValLoss:  1.9967776536941528 \n","\n","Epoch  480 TrAcc:  0.8551858646473133 ValAcc:  0.19117471190205584 TrLoss:  0.0972423180937767 ValLoss:  2.396585464477539 \n","\n","Epoch  481 TrAcc:  0.9144346652365789 ValAcc:  0.1972550216568643 TrLoss:  0.04652399197220802 ValLoss:  2.3050637245178223 \n","\n","Epoch  482 TrAcc:  0.7958093835685733 ValAcc:  0.1940577685938875 TrLoss:  0.24954156577587128 ValLoss:  2.0542373657226562 \n","\n","Epoch  483 TrAcc:  0.7005432744072989 ValAcc:  0.19785646878501437 TrLoss:  0.15544497966766357 ValLoss:  2.3774256706237793 \n","\n","Epoch  484 TrAcc:  0.8119826218139741 ValAcc:  0.19841225150991468 TrLoss:  0.06676089763641357 ValLoss:  2.307868719100952 \n","\n","Epoch  485 TrAcc:  0.9004185381055021 ValAcc:  0.19636796172193768 TrLoss:  0.040207408368587494 ValLoss:  2.088028907775879 \n","\n","Epoch  486 TrAcc:  0.9577081846524872 ValAcc:  0.20308806603480034 TrLoss:  0.02985512465238571 ValLoss:  2.3731846809387207 \n","\n","Epoch  487 TrAcc:  0.9836668966345757 ValAcc:  0.19404239187742287 TrLoss:  0.01701817288994789 ValLoss:  2.333183765411377 \n","\n","Epoch  488 TrAcc:  0.9923700539034924 ValAcc:  0.19734900598600924 TrLoss:  0.011235334910452366 ValLoss:  2.184206962585449 \n","\n","Epoch  489 TrAcc:  0.9967788881602426 ValAcc:  0.19102286594465676 TrLoss:  0.00792838167399168 ValLoss:  2.2736082077026367 \n","\n","Epoch  490 TrAcc:  0.9984237435358758 ValAcc:  0.18518178298113766 TrLoss:  0.007094212807714939 ValLoss:  2.365546703338623 \n","\n","Epoch  491 TrAcc:  0.9987824759492958 ValAcc:  0.19065660862454892 TrLoss:  0.005240348167717457 ValLoss:  2.519669532775879 \n","\n","Epoch  492 TrAcc:  0.9990195707070706 ValAcc:  0.19238864600867592 TrLoss:  0.0051893917843699455 ValLoss:  2.273956775665283 \n","\n","Epoch  493 TrAcc:  0.9992828395562771 ValAcc:  0.19830198196143714 TrLoss:  0.005458827130496502 ValLoss:  2.2361440658569336 \n","\n","Epoch  494 TrAcc:  0.9993619791666667 ValAcc:  0.19376311538515298 TrLoss:  0.005270504392683506 ValLoss:  2.4887404441833496 \n","\n","Epoch  495 TrAcc:  0.999578373015873 ValAcc:  0.19663593161601378 TrLoss:  0.005933394655585289 ValLoss:  2.1382317543029785 \n","\n","Epoch  496 TrAcc:  0.9997265625 ValAcc:  0.20118643113494897 TrLoss:  0.005230211652815342 ValLoss:  2.3006157875061035 \n","\n","Epoch  497 TrAcc:  0.9997265625 ValAcc:  0.19814539139088097 TrLoss:  0.005354246124625206 ValLoss:  2.3573226928710938 \n","\n","Epoch  498 TrAcc:  0.9995479910714287 ValAcc:  0.19862437102765865 TrLoss:  0.00438434025272727 ValLoss:  2.3817930221557617 \n","\n","Epoch  499 TrAcc:  0.9995182291666667 ValAcc:  0.19172579248023144 TrLoss:  0.009691470302641392 ValLoss:  2.20729398727417 \n","\n","Epoch  500 TrAcc:  0.9996074054621849 ValAcc:  0.18638647908420503 TrLoss:  0.005564004648476839 ValLoss:  2.37614369392395 \n","\n","Epochs: 500, Iterations: 12500, Batch Size: 64, Learning Rate: 0.001\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"stream","text":["Final Training Accuracy: 0.9996074054621849\n","Final Validation Accuracy: 0.18638647908420503\n","Final Training Loss: 0.005564004648476839\n","Final Validation Loss: 2.37614369392395\n","Final Epochs: 500\n","Final Iterations: 12500\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ycZw1EdWHGjX"},"source":["##Inspecting Model Output "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8fZxmwodCM5e","executionInfo":{"status":"ok","timestamp":1617594389971,"user_tz":240,"elapsed":4399,"user":{"displayName":"Mirza N","photoUrl":"","userId":"15555699542914153836"}},"outputId":"6d5572dc-418d-4665-e1e3-be2e044d3946"},"source":["best_model = MusicSheetCRNN().cuda()\n","model_path = '/content/bestmodel_MusicSheetCRNN_bs64_lr0.001'\n","state = torch.load(model_path)\n","best_model.load_state_dict(state)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{"tags":[]},"execution_count":42}]},{"cell_type":"code","metadata":{"id":"VPfMu_umLRkV"},"source":["def convert_int_to_notes(ints):\n","  return [noteDict.get(int(i)) for i in ints]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":285},"id":"9rt2wyK4fcXl","executionInfo":{"status":"ok","timestamp":1617594515238,"user_tz":240,"elapsed":1403,"user":{"displayName":"Mirza N","photoUrl":"","userId":"15555699542914153836"}},"outputId":"7159d889-79a8-4037-e4fc-39748cac265d"},"source":["model = best_model\n","criterion = nn.CTCLoss(blank_label, zero_infinity=True)\n","for imgs, labels in validation_loader:\n","  #labels = inject_note_breaks(labels)\n","  out_lengths = torch.IntTensor(batch_size).fill_(model.cnn_output_width)\n","  labels_lengths = torch.IntTensor([len(t) for t in labels])\n","\n","  #############################################\n","  #To Enable GPU Usage\n","  if use_cuda and torch.cuda.is_available():\n","    imgs = imgs.cuda()\n","    labels = labels.cuda()\n","    out_lengths = out_lengths.cuda()\n","    labels_lengths = labels_lengths.cuda()\n","  #############################################\n","  plt.imshow(imgs[0].cpu().permute(1, 2, 0))\n","  out = model(imgs)\n","  out = out.permute(1, 0, 2)\n","  out = F.log_softmax(out, dim=-1)\n","  #print(labels_lengths.shape)\n","  #print(criterion(out, labels, out_lengths, labels_lengths))\n","  #print(out)\n","  #print(labels)\n","  _, max_index = torch.max(out, dim=2)\n","  #print(max_index)\n","  total_correct_notes = 0\n","  for i in range(1):\n","    raw_prediction = list(max_index[:, i].detach().cpu().numpy())\n","    print(\"raw prediction:\", raw_prediction)\n","    prediction = torch.FloatTensor([c for c, _ in groupby(raw_prediction) if c != blank_label and c != 0])\n","    if use_cuda and torch.cuda.is_available():\n","      prediction = prediction.cuda()\n","    print(\"prediction:\", prediction)\n","    curr_label = labels[i]\n","    correct_label = curr_label[curr_label.nonzero().squeeze()]\n","    print(\"encoded label:\", correct_label)\n","    correct_notes = 0\n","    if len(prediction) < len(correct_label):\n","      num_notes = len(prediction)\n","    else:\n","      num_notes = len(correct_label)\n","    for j in range(num_notes):\n","      if prediction[j] == correct_label[j]:\n","        correct_notes += 1\n","    total_correct_notes += len(correct_label)\n","    if len(prediction) == len(correct_label) and torch.all(prediction.eq(correct_label)):\n","      print(\"correct\")\n","    else:\n","      print(len(prediction))\n","      print(len(correct_label))\n","  print(correct_notes / total_correct_notes)\n","  print(\"label:\", convert_int_to_notes(correct_label))\n","  print(\"model prediction:\", convert_int_to_notes(prediction))\n","  break"],"execution_count":null,"outputs":[{"output_type":"stream","text":["raw prediction: [62, 91, 62, 66, 91, 67, 67, 71, 71, 91, 91, 91, 91, 67, 69, 67, 91, 91, 69, 91, 91, 91, 91, 67, 91, 71, 71, 71, 71, 0, 0, 91, 0, 0, 91, 91, 0, 0, 91, 91, 0, 0, 91, 91, 0, 0, 91, 91, 0, 0, 91, 91, 0, 0, 91, 91, 0, 0, 91, 91, 0, 0, 0, 91, 91, 0, 0, 91, 91, 0, 0, 91, 91, 0, 0, 91, 91, 0, 0, 91, 91, 0, 0, 0, 91, 91, 0, 0, 91, 91, 0, 0, 91, 91, 91, 0, 0, 0, 0, 0, 91, 91, 0, 0, 91, 91, 0, 0, 0, 91, 91, 0, 0, 91, 0, 0, 0, 91, 91, 0, 0, 91, 91, 0, 91, 0, 91, 0, 91, 0, 91, 0, 91, 0, 91, 0, 91, 0, 91, 0, 91, 0, 91, 0, 91, 0]\n","prediction: tensor([62., 62., 66., 67., 71., 67., 69., 67., 69., 67., 71.],\n","       device='cuda:0')\n","encoded label: tensor([62., 67., 71., 69., 67., 66., 67., 69., 71., 72., 71., 69.],\n","       device='cuda:0')\n","11\n","12\n","0.16666666666666666\n","label: ['D4', 'G4', 'B4', 'A4', 'G4', 'F#4', 'G4', 'A4', 'B4', 'C5', 'B4', 'A4']\n","model prediction: ['D4', 'D4', 'F#4', 'G4', 'B4', 'G4', 'A4', 'G4', 'A4', 'G4', 'B4']\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"NbPWLun6Nq9E"},"source":["##Evaluated on New Never Before Seen Data"]},{"cell_type":"code","metadata":{"id":"vjzThWWRPBWg"},"source":["  img = plt.imread('/content/someoneyouloved.png')\n","  img_cropped = img[0:154, 0:1200]\n","  plt.imshow(img_cropped)\n","  out = best_model(torch.FloatTensor(img_cropped).permute(2, 1, 0).unsqueeze(0).cuda())\n","  out = out.permute(1, 0, 2)\n","  out = F.log_softmax(out, dim=-1)\n","  _, max_index = torch.max(out, dim=2)\n","\n","  raw_prediction = list(max_index[:, 0].detach().cpu().numpy())\n","  print(\"raw prediction:\", raw_prediction)\n","  prediction = torch.FloatTensor([c for c, _ in groupby(raw_prediction) if c != blank_label and c != 0])\n","  if use_cuda and torch.cuda.is_available():\n","    prediction = prediction.cuda()\n","  print(\"prediction:\", prediction)\n","  print(\"decoded model prediction:\", convert_int_to_notes(prediction))\n","    "],"execution_count":null,"outputs":[]}]}